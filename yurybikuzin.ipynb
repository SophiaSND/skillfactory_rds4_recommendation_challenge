{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(df, field_name):\n",
    "    print(f\"Колонка \\\"{field_name}\\\":\")\n",
    "    print(\"------\")\n",
    "    print(\"na:\", df[field_name].isna().sum())\n",
    "    print(\"уникальных значений:\", len(df[field_name].unique()))\n",
    "    print(\"------\")\n",
    "    print(df[field_name].value_counts())  \n",
    "    \n",
    "def param_data(data): # посмотрим на данные\n",
    "    \"\"\"dataset required parameters \"\"\"\n",
    "    param = pd.DataFrame({\n",
    "              'dtypes': data.dtypes.values,\n",
    "              'nunique': data.nunique().values,\n",
    "              'isna': data.isna().sum().values,\n",
    "              'loc[0]': data.loc[0].values,\n",
    "              }, \n",
    "             index = data.loc[0].index)\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42003 entries, 0 to 42002\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   itemid       42003 non-null  int64 \n",
      " 1   brand        41574 non-null  object\n",
      " 2   description  38588 non-null  object\n",
      " 3   title        42003 non-null  object\n",
      " 4   main_cat     41920 non-null  object\n",
      " 5   price        25786 non-null  object\n",
      " 6   is_train     42003 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 2.0+ MB\n",
      "None    itemid                  brand  \\\n",
      "0       1                 Lipton   \n",
      "1       0                 Lipton   \n",
      "2       2            Organo Gold   \n",
      "3       3               Mae Ploy   \n",
      "4       4  Harold Import Company   \n",
      "\n",
      "                                         description  \\\n",
      "0  Lipton Yellow Label Tea use only the finest te...   \n",
      "1  Lipton Yellow Label Teabags uses a new way to ...   \n",
      "2  20 Sachets\\n\\nEmpty contents into cup\\nPour 8o...   \n",
      "3  Mae Ploy Thai green curry paste.\\n\\nIngredient...   \n",
      "4  This set is a great value from one of the grea...   \n",
      "\n",
      "                                               title     main_cat   price  \\\n",
      "0         Lipton Yellow Label Tea (loose tea) - 450g      Grocery  $12.46   \n",
      "1  Lipton Yellow Label Finest Blend Tea Bags 100 ...      Grocery  $12.98   \n",
      "2  Organo Gold Cafe Supreme 100% Certified Ganode...      Grocery  $29.90   \n",
      "3                  Mae Ploy Green Curry Paste, 14 oz      Grocery     NaN   \n",
      "4                  Ateco Food Coloring Kit, 6 colors  Amazon Home     NaN   \n",
      "\n",
      "   is_train  \n",
      "0      True  \n",
      "1      True  \n",
      "2      True  \n",
      "3      True  \n",
      "4      True  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 166917 entries, 0 to 166916\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   itemid    166917 non-null  int64 \n",
      " 1   category  166917 non-null  object\n",
      " 2   is_train  166917 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(1)\n",
      "memory usage: 2.7+ MB\n",
      "None    itemid                category  is_train\n",
      "0       1  Grocery & Gourmet Food      True\n",
      "1       1               Beverages      True\n",
      "2       1     Coffee, Tea & Cocoa      True\n",
      "3       1                     Tea      True\n",
      "4       1                   Black      True\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178606 entries, 0 to 178605\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count   Dtype\n",
      "---  ------            --------------   -----\n",
      " 0   itemid            178606 non-null  int64\n",
      " 1   also_view_itemid  178606 non-null  int64\n",
      " 2   is_train          178606 non-null  bool \n",
      "dtypes: bool(1), int64(2)\n",
      "memory usage: 2.9 MB\n",
      "None    itemid  also_view_itemid  is_train\n",
      "0       1              9433      True\n",
      "1       1              2990      True\n",
      "2       1             10750      True\n",
      "3       1             19204      True\n",
      "4       1              2991      True\n"
     ]
    }
   ],
   "source": [
    "# from meta_Grocery_and_Gourmet_Food.json\n",
    "\n",
    "# try:\n",
    "#     json\n",
    "# except NameError:\n",
    "#     json = pd.read_csv('data/json.csv.zip', low_memory=False)\n",
    "# print(json.info(), json.head())\n",
    "\n",
    "force_reload = False\n",
    "# infix = ''\n",
    "infix = '_used'\n",
    "suffix = '.zip'\n",
    "try:\n",
    "    normalized\n",
    "    if force_reload:\n",
    "        raise NameError('force_load')\n",
    "except NameError:\n",
    "    normalized = pd.read_csv(f'data/normalized{infix}.csv{suffix}', low_memory=False)\n",
    "print(normalized.info(), normalized.head())\n",
    "    \n",
    "try:\n",
    "    category\n",
    "    if force_reload:\n",
    "        raise NameError('force_load')\n",
    "except NameError:\n",
    "    category = pd.read_csv(f'data/category{infix}.csv{suffix}', low_memory=False)\n",
    "print(category.info(), category.head())\n",
    "    \n",
    "try:\n",
    "    also_view\n",
    "    if force_reload:\n",
    "        raise NameError('force_load')\n",
    "except NameError:\n",
    "    also_view = pd.read_csv(f'data/also_view{infix}.csv{suffix}', low_memory=False)\n",
    "print(also_view.info(), also_view.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== price\n",
      "count      25786\n",
      "unique      4603\n",
      "top       $14.99\n",
      "freq         583\n",
      "Name: price, dtype: object\n",
      "===== brand\n",
      "count              41574\n",
      "unique              8869\n",
      "top       Bob's Red Mill\n",
      "freq                 341\n",
      "Name: brand, dtype: object\n",
      "===== description\n",
      "count                                                 38588\n",
      "unique                                                36543\n",
      "top       Our mission is to be the leader in importing a...\n",
      "freq                                                     50\n",
      "Name: description, dtype: object\n",
      "===== title\n",
      "count                                                 42003\n",
      "unique                                                41167\n",
      "top       Alvita Caffeine Free Alfalfa Leaf Tea - 24 Tea...\n",
      "freq                                                      5\n",
      "Name: title, dtype: object\n",
      "===== main_cat\n",
      "count       41920\n",
      "unique         17\n",
      "top       Grocery\n",
      "freq        39807\n",
      "Name: main_cat, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for field_name in [\"price\", \"brand\", \"description\", \"title\", \"main_cat\"]:\n",
    "    print(\"=====\", field_name);\n",
    "    print(normalized[field_name].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Grocery &amp; Gourmet Food</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee, Tea &amp; Cocoa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Tea</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid                category  is_train\n",
       "0       1  Grocery & Gourmet Food      True\n",
       "1       1               Beverages      True\n",
       "2       1     Coffee, Tea & Cocoa      True\n",
       "3       1                     Tea      True\n",
       "4       1                   Black      True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">↓ ОБУЧАЮЩАЯ ВЫБОРКА ↓ (826895, 14)</th>\n",
       "      <th colspan=\"4\" halign=\"left\">↓ ТЕСТОВАЯ ВЫБОРКА ↓ (285965, 11)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>dtypes</th>\n",
       "      <th>nunique</th>\n",
       "      <th>isna</th>\n",
       "      <th>loc[0]</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>nunique</th>\n",
       "      <th>isna</th>\n",
       "      <th>loc[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>float64</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verified</th>\n",
       "      <td>bool</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>bool</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewTime</th>\n",
       "      <td>object</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10 4, 2016</td>\n",
       "      <td>object</td>\n",
       "      <td>4349.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10 1, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>object</td>\n",
       "      <td>41302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B01CPNIEQG</td>\n",
       "      <td>object</td>\n",
       "      <td>37876.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B001E5E3X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerName</th>\n",
       "      <td>object</td>\n",
       "      <td>101207.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Heather</td>\n",
       "      <td>object</td>\n",
       "      <td>86815.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Rudys Mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewText</th>\n",
       "      <td>object</td>\n",
       "      <td>686739.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>These are my FAVORITE spices in my collection....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>object</td>\n",
       "      <td>411451.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>Must Add to your Spice kitchen!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unixReviewTime</th>\n",
       "      <td>int64</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1475539200</td>\n",
       "      <td>int64</td>\n",
       "      <td>4349.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1475280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>object</td>\n",
       "      <td>311.0</td>\n",
       "      <td>712944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>object</td>\n",
       "      <td>198.0</td>\n",
       "      <td>246503.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>style</th>\n",
       "      <td>object</td>\n",
       "      <td>25892.0</td>\n",
       "      <td>398698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>object</td>\n",
       "      <td>18904.0</td>\n",
       "      <td>138285.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>object</td>\n",
       "      <td>6636.0</td>\n",
       "      <td>819916.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>object</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>283597.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <td>int64</td>\n",
       "      <td>127448.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102179</td>\n",
       "      <td>int64</td>\n",
       "      <td>109357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemid</th>\n",
       "      <td>int64</td>\n",
       "      <td>41302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37138</td>\n",
       "      <td>int64</td>\n",
       "      <td>37876.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>float64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int64</td>\n",
       "      <td>285965.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ↓ ОБУЧАЮЩАЯ ВЫБОРКА ↓ (826895, 14)                      \\\n",
       "                                           dtypes   nunique      isna   \n",
       "overall                                   float64       5.0       0.0   \n",
       "verified                                     bool       2.0       0.0   \n",
       "reviewTime                                 object    4580.0       0.0   \n",
       "asin                                       object   41302.0       0.0   \n",
       "reviewerName                               object  101207.0     164.0   \n",
       "reviewText                                 object  686739.0     274.0   \n",
       "summary                                    object  411451.0     166.0   \n",
       "unixReviewTime                              int64    4580.0       0.0   \n",
       "vote                                       object     311.0  712944.0   \n",
       "style                                      object   25892.0  398698.0   \n",
       "image                                      object    6636.0  819916.0   \n",
       "userid                                      int64  127448.0       0.0   \n",
       "itemid                                      int64   41302.0       0.0   \n",
       "rating                                    float64       2.0       0.0   \n",
       "Id                                            NaN       NaN       NaN   \n",
       "\n",
       "                                                                   \\\n",
       "                                                           loc[0]   \n",
       "overall                                                         5   \n",
       "verified                                                     True   \n",
       "reviewTime                                             10 4, 2016   \n",
       "asin                                                   B01CPNIEQG   \n",
       "reviewerName                                              Heather   \n",
       "reviewText      These are my FAVORITE spices in my collection....   \n",
       "summary                           Must Add to your Spice kitchen!   \n",
       "unixReviewTime                                         1475539200   \n",
       "vote                                                          NaN   \n",
       "style                                                         NaN   \n",
       "image                                                         NaN   \n",
       "userid                                                     102179   \n",
       "itemid                                                      37138   \n",
       "rating                                                          1   \n",
       "Id                                                            NaN   \n",
       "\n",
       "               ↓ ТЕСТОВАЯ ВЫБОРКА ↓ (285965, 11)                      \\\n",
       "                                          dtypes   nunique      isna   \n",
       "overall                                      NaN       NaN       NaN   \n",
       "verified                                    bool       2.0       0.0   \n",
       "reviewTime                                object    4349.0       0.0   \n",
       "asin                                      object   37876.0       0.0   \n",
       "reviewerName                              object   86815.0      47.0   \n",
       "reviewText                                   NaN       NaN       NaN   \n",
       "summary                                      NaN       NaN       NaN   \n",
       "unixReviewTime                             int64    4349.0       0.0   \n",
       "vote                                      object     198.0  246503.0   \n",
       "style                                     object   18904.0  138285.0   \n",
       "image                                     object    2306.0  283597.0   \n",
       "userid                                     int64  109357.0       0.0   \n",
       "itemid                                     int64   37876.0       0.0   \n",
       "rating                                       NaN       NaN       NaN   \n",
       "Id                                         int64  285965.0       0.0   \n",
       "\n",
       "                            \n",
       "                    loc[0]  \n",
       "overall                NaN  \n",
       "verified              True  \n",
       "reviewTime      10 1, 2016  \n",
       "asin            B001E5E3X0  \n",
       "reviewerName     Rudys Mom  \n",
       "reviewText             NaN  \n",
       "summary                NaN  \n",
       "unixReviewTime  1475280000  \n",
       "vote                   NaN  \n",
       "style                  NaN  \n",
       "image                  NaN  \n",
       "userid               68877  \n",
       "itemid                7506  \n",
       "rating                 NaN  \n",
       "Id                       0  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/1592565/determine-if-variable-is-defined-in-python/1592578#1592578\n",
    "try:\n",
    "    train\n",
    "except NameError:\n",
    "    train = pd.read_csv('data/train.csv.zip', low_memory=False)\n",
    "    train = train.drop_duplicates().reset_index(drop = True) # удалим дубликаты, если есть\n",
    "\n",
    "try:\n",
    "    test\n",
    "except NameError:\n",
    "    test = pd.read_csv('data/test.csv.zip', low_memory=False)\n",
    "\n",
    "try:\n",
    "    submission\n",
    "except NameError:\n",
    "    submission = pd.read_csv('data/sample_submission.csv.zip', low_memory=False)\n",
    "    \n",
    "# is_loaded = True\n",
    "# if not is_loaded:\n",
    "#     train = pd.read_csv('data/train.csv.zip', low_memory=False)\n",
    "#     test = pd.read_csv('data/test.csv.zip', low_memory=False)\n",
    "#     is_loaded = True\n",
    "#     submission = pd.read_csv('data/sample_submission.csv.zip', low_memory=False)\n",
    "pd.concat([param_data(train), param_data(test)], \n",
    "          axis=1, \n",
    "          keys = [f'↓ ОБУЧАЮЩАЯ ВЫБОРКА ↓ {train.shape}', f'↓ ТЕСТОВАЯ ВЫБОРКА ↓ {test.shape}'],  \n",
    "          sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание датасета:\n",
    "\n",
    "    overall - рейтинг, который поставил пользователь (значения от 1 до 5)\n",
    "    verified - был ли отзыв верифицирован (значения True или False)\n",
    "    reviewTime - когда был отзыв написан\n",
    "    asin - предположительно, серийный номер или штрихкод\n",
    "    reviewerName - имя пользователя\n",
    "    reviewText - текст отзыва\n",
    "    summary - сжатый отзыв\n",
    "    unixReviewTime - когда был отзыв написан в формате unix\n",
    "    vote - количество голосований за отзыв (значения - целые числа, представленные в виде строки)\n",
    "    style - метаданные ( значения словари с описанием размера порции и аромата продукта)\n",
    "    image - изображение продукта\n",
    "    userid - id пользователя\n",
    "    itemid - id товара\n",
    "    rating - предположительно, это понравился или не понравился товар, значения (1, если overall>=4 или 0) - target???\n",
    "    Id - id для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 826895 entries, 0 to 826894\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         826895 non-null  float64\n",
      " 1   verified        826895 non-null  bool   \n",
      " 2   reviewTime      826895 non-null  object \n",
      " 3   asin            826895 non-null  object \n",
      " 4   reviewerName    826731 non-null  object \n",
      " 5   reviewText      826621 non-null  object \n",
      " 6   summary         826729 non-null  object \n",
      " 7   unixReviewTime  826895 non-null  int64  \n",
      " 8   vote            113951 non-null  object \n",
      " 9   style           428197 non-null  object \n",
      " 10  image           6979 non-null    object \n",
      " 11  userid          826895 non-null  int64  \n",
      " 12  itemid          826895 non-null  int64  \n",
      " 13  rating          826895 non-null  float64\n",
      "dtypes: bool(1), float64(2), int64(3), object(8)\n",
      "memory usage: 82.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grocery                      39807\n",
      "Health & Personal Care        1212\n",
      "Amazon Home                    532\n",
      "All Beauty                     131\n",
      "Sports & Outdoors               72\n",
      "Industrial & Scientific         62\n",
      "Toys & Games                    46\n",
      "Office Products                 34\n",
      "Pet Supplies                     8\n",
      "Tools & Home Improvement         4\n",
      "Arts, Crafts & Sewing            4\n",
      "Baby                             3\n",
      "Software                         1\n",
      "Home Audio & Theater             1\n",
      "Cell Phones & Accessories        1\n",
      "Camera & Photo                   1\n",
      "Musical Instruments              1\n",
      "Name: main_cat, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 826895 entries, 0 to 826894\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         826895 non-null  float64\n",
      " 1   verified        826895 non-null  bool   \n",
      " 2   reviewTime      826895 non-null  object \n",
      " 3   asin            826895 non-null  object \n",
      " 4   reviewerName    826731 non-null  object \n",
      " 5   reviewText      826621 non-null  object \n",
      " 6   summary         826729 non-null  object \n",
      " 7   unixReviewTime  826895 non-null  int64  \n",
      " 8   vote            113951 non-null  object \n",
      " 9   style           428197 non-null  object \n",
      " 10  image           6979 non-null    object \n",
      " 11  userid          826895 non-null  int64  \n",
      " 12  itemid          826895 non-null  int64  \n",
      " 13  rating          826895 non-null  float64\n",
      "dtypes: bool(1), float64(2), int64(3), object(8)\n",
      "memory usage: 82.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 783219 entries, 0 to 826894\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         783219 non-null  float64\n",
      " 1   verified        783219 non-null  bool   \n",
      " 2   reviewTime      783219 non-null  object \n",
      " 3   asin            783219 non-null  object \n",
      " 4   reviewerName    783060 non-null  object \n",
      " 5   reviewText      782959 non-null  object \n",
      " 6   summary         783063 non-null  object \n",
      " 7   unixReviewTime  783219 non-null  int64  \n",
      " 8   vote            107191 non-null  object \n",
      " 9   style           404777 non-null  object \n",
      " 10  image           6391 non-null    object \n",
      " 11  userid          783219 non-null  int64  \n",
      " 12  itemid          783219 non-null  int64  \n",
      " 13  rating          783219 non-null  float64\n",
      " 14  is_grocery      783219 non-null  bool   \n",
      "dtypes: bool(2), float64(2), int64(3), object(8)\n",
      "memory usage: 85.2+ MB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(normalized.main_cat.value_counts())\n",
    "normalized_grocery = normalized[normalized.main_cat == 'Grocery']\n",
    "itemid_grocery_set = set(normalized_grocery.itemid.unique().tolist())\n",
    "train_grocery = train.copy()\n",
    "train_grocery['is_grocery'] = train_grocery.itemid.apply(lambda x: x in itemid_grocery_set)\n",
    "train_grocery = train_grocery[train_grocery.is_grocery]\n",
    "print(train.info(), train_grocery.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grocery & Gourmet Food    39807\n",
      "Beverages                  8979\n",
      "Coffee, Tea & Cocoa        6836\n",
      "Cooking & Baking           6060\n",
      "Candy & Chocolate          5335\n",
      "                          ...  \n",
      "Portabello                    1\n",
      "Ground Chicken                1\n",
      "Egg Whites                    1\n",
      "Turnips                       1\n",
      "Light Cream                   1\n",
      "Name: category, Length: 989, dtype: int64\n",
      "Beverages              8979\n",
      "Coffee, Tea & Cocoa    6836\n",
      "Cooking & Baking       6060\n",
      "Candy & Chocolate      5335\n",
      "Snack Foods            4637\n",
      "                       ... \n",
      "Portabello                1\n",
      "Ground Chicken            1\n",
      "Egg Whites                1\n",
      "Turnips                   1\n",
      "Light Cream               1\n",
      "Name: category, Length: 988, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_grocery = category.copy()\n",
    "category_grocery['is_grocery'] = category_grocery.itemid.apply(\n",
    "    lambda x: x in itemid_grocery_set)\n",
    "category_grocery = category_grocery[category_grocery.is_grocery]\n",
    "print(category_grocery.category.value_counts())\n",
    "category_grocery = category_grocery[category_grocery.category != 'Grocery & Gourmet Food']\n",
    "print(category_grocery.category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grocery & Gourmet Food                                                                                                                                                                                                                               42003\n",
       "Beverages                                                                                                                                                                                                                                             9674\n",
       "Coffee, Tea & Cocoa                                                                                                                                                                                                                                   7318\n",
       "Cooking & Baking                                                                                                                                                                                                                                      6720\n",
       "Candy & Chocolate                                                                                                                                                                                                                                     5518\n",
       "                                                                                                                                                                                                                                                     ...  \n",
       "Picky eaters? No problem! Banza chickpea pasta tastes, looks and cooks more like traditional pasta than other alternative pastas, including lentil pasta, quinoa pasta, black bean pasta, edamame pasta, brown rice pasta, and whole wheat pasta.        1\n",
       "Plum Sauce                                                                                                                                                                                                                                               1\n",
       "Carnations                                                                                                                                                                                                                                               1\n",
       "Rib Roast                                                                                                                                                                                                                                                1\n",
       "A favorite among Kristen Bell and Robin Roberts, Banza has been featured in TIME Magazines 25 Best Inventions of 2015, the New York Times, Food & Wine Magazine, the Today Show, Huffington Post, Good Morning America, and Generation Startup.          1\n",
       "Name: category, Length: 1003, dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     270080\n",
      "False     15885\n",
      "Name: is_grocery, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 285965 entries, 0 to 285964\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   verified        285965 non-null  bool  \n",
      " 1   reviewTime      285965 non-null  object\n",
      " 2   asin            285965 non-null  object\n",
      " 3   reviewerName    285918 non-null  object\n",
      " 4   unixReviewTime  285965 non-null  int64 \n",
      " 5   vote            39462 non-null   object\n",
      " 6   style           147680 non-null  object\n",
      " 7   image           2368 non-null    object\n",
      " 8   userid          285965 non-null  int64 \n",
      " 9   itemid          285965 non-null  int64 \n",
      " 10  Id              285965 non-null  int64 \n",
      "dtypes: bool(1), int64(4), object(6)\n",
      "memory usage: 22.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15885 entries, 3 to 285952\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   verified        15885 non-null  bool  \n",
      " 1   reviewTime      15885 non-null  object\n",
      " 2   asin            15885 non-null  object\n",
      " 3   reviewerName    15883 non-null  object\n",
      " 4   unixReviewTime  15885 non-null  int64 \n",
      " 5   vote            2392 non-null   object\n",
      " 6   style           8737 non-null   object\n",
      " 7   image           189 non-null    object\n",
      " 8   userid          15885 non-null  int64 \n",
      " 9   itemid          15885 non-null  int64 \n",
      " 10  Id              15885 non-null  int64 \n",
      " 11  is_grocery      15885 non-null  bool  \n",
      "dtypes: bool(2), int64(4), object(6)\n",
      "memory usage: 1.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 270080 entries, 0 to 285964\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   verified        270080 non-null  bool  \n",
      " 1   reviewTime      270080 non-null  object\n",
      " 2   asin            270080 non-null  object\n",
      " 3   reviewerName    270035 non-null  object\n",
      " 4   unixReviewTime  270080 non-null  int64 \n",
      " 5   vote            37070 non-null   object\n",
      " 6   style           138943 non-null  object\n",
      " 7   image           2179 non-null    object\n",
      " 8   userid          270080 non-null  int64 \n",
      " 9   itemid          270080 non-null  int64 \n",
      " 10  Id              270080 non-null  int64 \n",
      " 11  is_grocery      270080 non-null  bool  \n",
      "dtypes: bool(2), int64(4), object(6)\n",
      "memory usage: 23.2+ MB\n",
      "None None None\n"
     ]
    }
   ],
   "source": [
    "test_grocery = test.copy()\n",
    "test_grocery['is_grocery'] = test_grocery.itemid.apply(\n",
    "    lambda x: x in itemid_grocery_set)\n",
    "print(test_grocery['is_grocery'].value_counts())\n",
    "test_grocery_non = test_grocery[test_grocery.is_grocery == False]\n",
    "test_grocery = test_grocery[test_grocery.is_grocery == True]\n",
    "print(test.info(), test_grocery_non.info(), test_grocery.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health & Personal Care       1095\n",
      "Amazon Home                   480\n",
      "All Beauty                    117\n",
      "Sports & Outdoors              69\n",
      "Industrial & Scientific        59\n",
      "Toys & Games                   38\n",
      "Office Products                32\n",
      "Pet Supplies                    6\n",
      "Tools & Home Improvement        4\n",
      "Arts, Crafts & Sewing           4\n",
      "Baby                            3\n",
      "Camera & Photo                  1\n",
      "Software                        1\n",
      "Home Audio & Theater            1\n",
      "Cell Phones & Accessories       1\n",
      "Musical Instruments             1\n",
      "Name: main_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "itemid_test_grocery_non = set(test_grocery_non.itemid.unique().tolist())\n",
    "normalized_test_grocery_non = normalized.copy()\n",
    "normalized_test_grocery_non['test_grocery_non'] = normalized_test_grocery_non.itemid.apply(\n",
    "    lambda x: x in itemid_test_grocery_non)\n",
    "normalized_test_grocery_non = normalized_test_grocery_non[normalized_test_grocery_non.test_grocery_non]\n",
    "print(normalized_test_grocery_non.main_cat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    826895.000000\n",
      "mean          0.848490\n",
      "std           0.358546\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max           1.000000\n",
      "Name: rating, dtype: float64\n",
      "[1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "field_name = 'rating'\n",
    "print(train[field_name].describe())\n",
    "print(train[field_name].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# itemid_asin = train[['itemid', 'asin']]\n",
    "# itemid_asin_test = test[['itemid', 'asin']]\n",
    "# print(itemid_asin.info(), itemid_asin_test.info())\n",
    "# itemid_asin = itemid_asin.drop_duplicates().reset_index(drop = True)\n",
    "# itemid_asin_test = itemid_asin_test.drop_duplicates().reset_index(drop = True)\n",
    "# print(itemid_asin.info(), itemid_asin_test.info())\n",
    "# itemid_asin_concat = pd.concat([itemid_asin, itemid_asin_test]).drop_duplicates().reset_index(drop = True)\n",
    "# print(itemid_asin_concat.info())\n",
    "# itemid_asin_concat.to_csv('data/itemid_asin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41302 entries, 0 to 41301\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   itemid  41302 non-null  int64 \n",
      " 1   asin    41302 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 645.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "itemid_asin = train[['itemid', 'asin']]\n",
    "# itemid_asin_test = test[['itemid', 'asin']]\n",
    "# print(itemid_asin.info(), itemid_asin_test.info())\n",
    "itemid_asin = itemid_asin.drop_duplicates().reset_index(drop = True)\n",
    "# itemid_asin_test = itemid_asin_test.drop_duplicates().reset_index(drop = True)\n",
    "# print(itemid_asin.info(), itemid_asin_test.info())\n",
    "# itemid_asin_concat = pd.concat([itemid_asin, itemid_asin_test]).drop_duplicates().reset_index(drop = True)\n",
    "print(itemid_asin.info())\n",
    "itemid_asin.to_csv('data/itemid_asin_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ полей исходного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отберем поля "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для обучающего датасета, поочередно рассматривая колонки исходного датасета:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overall - рейтинг, который поставил пользователь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"overall\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 5\n",
      "------\n",
      "5.0    592278\n",
      "4.0    109334\n",
      "3.0     58488\n",
      "1.0     36159\n",
      "2.0     30636\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'overall'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"rating_check\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 2\n",
      "------\n",
      "1.0    701612\n",
      "0.0    125283\n",
      "Name: rating_check, dtype: int64\n",
      "Колонка \"rating\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 2\n",
      "------\n",
      "1.0    701612\n",
      "0.0    125283\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['rating_check'] = train['overall'].apply(lambda x: 1.0 if x >= 4 else 0.0)\n",
    "describe(df, 'rating_check')\n",
    "describe(df, 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение этого поля отражено в колонке `rating`, не включаем его в список далее рассматриваемых"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"verified\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 2\n",
      "------\n",
      "True     718164\n",
      "False    108731\n",
      "Name: verified, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'verified'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Надо бы drop'нуть все неверифицированные отзывы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"asin\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 41302\n",
      "------\n",
      "B00BUKL666    5430\n",
      "B00D3M2QP4    4733\n",
      "B008QMX2SG    4611\n",
      "B00R7PWK7W    2449\n",
      "B000F4DKAI    2166\n",
      "              ... \n",
      "B000X21LT4       1\n",
      "B004VLVQGQ       1\n",
      "B00J7W0KCA       1\n",
      "B0014EQHR6       1\n",
      "B000ZU93N0       1\n",
      "Name: asin, Length: 41302, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'asin'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"itemid\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 41302\n",
      "------\n",
      "22208    5430\n",
      "23540    4733\n",
      "24556    4611\n",
      "32046    2449\n",
      "1919     2166\n",
      "         ... \n",
      "38777       1\n",
      "32616       1\n",
      "5396        1\n",
      "25613       1\n",
      "38602       1\n",
      "Name: itemid, Length: 41302, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "describe(df, 'itemid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что рассматриваемая колонка и `itemid`, это про одно и тоже - код товара, поэтому рассматриваемую колонку игонорируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewerName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"reviewerName\":\n",
      "------\n",
      "na: 164\n",
      "уникальных значений: 101208\n",
      "------\n",
      "Amazon Customer    30612\n",
      "Kindle Customer     6012\n",
      "Linda                713\n",
      "John                 695\n",
      "David                597\n",
      "                   ...  \n",
      "J. Gambuto             1\n",
      "S. Soresso             1\n",
      "chris rein oral        1\n",
      "A. Jermain             1\n",
      "Kay Jones              1\n",
      "Name: reviewerName, Length: 101207, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'reviewerName'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"userid\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 127448\n",
      "------\n",
      "842       418\n",
      "17987     311\n",
      "355       294\n",
      "2024      288\n",
      "2809      263\n",
      "         ... \n",
      "30644       1\n",
      "64828       1\n",
      "104926      1\n",
      "63804       1\n",
      "38947       1\n",
      "Name: userid, Length: 127448, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "describe(df, 'userid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поле `userid` выглядит точнее, чем рассматриваемая колонка, поэтому ее тоже игнорируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"reviewText\":\n",
      "------\n",
      "na: 274\n",
      "уникальных значений: 686740\n",
      "------\n",
      "good                                                                                                                                                                                                                                                                                                                         3019\n",
      "great                                                                                                                                                                                                                                                                                                                        2525\n",
      "Great                                                                                                                                                                                                                                                                                                                        2002\n",
      "Good                                                                                                                                                                                                                                                                                                                         1977\n",
      "ok                                                                                                                                                                                                                                                                                                                           1278\n",
      "                                                                                                                                                                                                                                                                                                                             ... \n",
      "You will eat the whole bag. Resistance is futile. Not too much guilt though, unlike the sleeve of oreos                                                                                                                                                                                                                         1\n",
      "Great flavor, soft but not sticky                                                                                                                                                                                                                                                                                               1\n",
      "Don't buy pl&aacute;tanos from Amazon. They're tiny. Pl&aacute;tanos at the grocery store are larger and cheaper. Also... pl&aacute;tanos are delicious so definitely buy them.                                                                                                                                                 1\n",
      "Amazingly tasty product. I'm in love. Will be mixing with my home-made cold-brew method coffee. I expect to be a very satisfied and continuing customer and would LOVE to do some 'product provided by vendor' type reviews for Teeccino. This flavor genuinely far surpassed my expectations. I'd love to help boost it!       1\n",
      "Original in a big bottle :)                                                                                                                                                                                                                                                                                                     1\n",
      "Name: reviewText, Length: 686739, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'reviewText'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"summary\":\n",
      "------\n",
      "na: 166\n",
      "уникальных значений: 411452\n",
      "------\n",
      "Five Stars                                                               167416\n",
      "Four Stars                                                                26010\n",
      "Three Stars                                                               11682\n",
      "One Star                                                                   5206\n",
      "Two Stars                                                                  4824\n",
      "                                                                          ...  \n",
      "Yummy at a Great Price                                                        1\n",
      "Authentic peach flavor in a great gummy!                                      1\n",
      "Wholesome and real with lots and lots of nuts.                                1\n",
      "... up with B&M Baked Beans and this was a great side for those times         1\n",
      "I add Great Lakes Gelatin to my morning Kefir smoothie                        1\n",
      "Name: summary, Length: 411451, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'summary'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unixReviewTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"unixReviewTime\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 4580\n",
      "------\n",
      "1456790400    909\n",
      "1468454400    858\n",
      "1433289600    769\n",
      "1453248000    764\n",
      "1455926400    753\n",
      "             ... \n",
      "1105142400      1\n",
      "1131062400      1\n",
      "1161993600      1\n",
      "1142467200      1\n",
      "1177113600      1\n",
      "Name: unixReviewTime, Length: 4580, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'unixReviewTime'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"reviewTime\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 4580\n",
      "------\n",
      "03 1, 2016     909\n",
      "07 14, 2016    858\n",
      "06 3, 2015     769\n",
      "01 20, 2016    764\n",
      "02 20, 2016    753\n",
      "              ... \n",
      "04 21, 2005      1\n",
      "04 16, 2004      1\n",
      "12 9, 2005       1\n",
      "12 29, 2006      1\n",
      "06 1, 2006       1\n",
      "Name: reviewTime, Length: 4580, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'reviewTime'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта колонка про то же самое, что и `unixReviewTime`, только в другом формате. Игнорируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"vote\":\n",
      "------\n",
      "na: 712944\n",
      "уникальных значений: 312\n",
      "------\n",
      "2        42820\n",
      "3        21447\n",
      "4        12337\n",
      "5         7932\n",
      "6         5480\n",
      "         ...  \n",
      "507          1\n",
      "266          1\n",
      "230          1\n",
      "140          1\n",
      "1,491        1\n",
      "Name: vote, Length: 311, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'vote'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"style\":\n",
      "------\n",
      "na: 398698\n",
      "уникальных значений: 25893\n",
      "------\n",
      "{'Size:': ' Pack of 1'}                                                      4549\n",
      "{'Package Quantity:': ' 1'}                                                  4461\n",
      "{'Package Type:': ' Standard Packaging'}                                     3860\n",
      "{'Size:': ' 1 Pack'}                                                         3688\n",
      "{'Size:': ' 24 Count'}                                                       3615\n",
      "                                                                             ... \n",
      "{'Size:': ' 3 Ounce', 'Flavor:': ' Cinnamon'}                                   1\n",
      "{'Size:': ' 2 Pack 16 Ounce Bag'}                                               1\n",
      "{'Size:': ' 4-Ounce Bags (Pack of 6)', 'Flavor:': \" Jumpin' Hot & Spicy\"}       1\n",
      "{'Size:': ' Large Jar', 'Flavor:': ' Basil'}                                    1\n",
      "{'Size:': ' 2.85 Ounce (pack of 4)', 'Flavor:': ' Steakhouse'}                  1\n",
      "Name: style, Length: 25892, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'style'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"image\":\n",
      "------\n",
      "na: 819916\n",
      "уникальных значений: 6637\n",
      "------\n",
      "['https://images-na.ssl-images-amazon.com/images/I/712zJIOTV5L._SY88.jpg']                                                                                                                                                                                                                                  6\n",
      "['https://images-na.ssl-images-amazon.com/images/I/71+Z1TA3eyL._SY88.jpg']                                                                                                                                                                                                                                  6\n",
      "['https://images-na.ssl-images-amazon.com/images/I/81h8Zc+1rzL._SY88.jpg']                                                                                                                                                                                                                                  5\n",
      "['https://images-na.ssl-images-amazon.com/images/I/81kah7EsJtL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/81YnU7oiOIL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/81j+y7+3NxL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/81RV96qYZvL._SY88.jpg']    5\n",
      "['https://images-na.ssl-images-amazon.com/images/I/41wx9Sn88cL._SY88.jpg']                                                                                                                                                                                                                                  5\n",
      "                                                                                                                                                                                                                                                                                                           ..\n",
      "['https://images-na.ssl-images-amazon.com/images/I/7108Uq0H5mL._SY88.jpg']                                                                                                                                                                                                                                  1\n",
      "['https://images-na.ssl-images-amazon.com/images/I/81RF2Qx5U7L._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71h3-JVEGRL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71pg01hp7CL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71Rh6-NoqDL._SY88.jpg']    1\n",
      "['https://images-na.ssl-images-amazon.com/images/I/51SwytL473L._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/51tSvsBfYcL._SY88.jpg']                                                                                                                                                        1\n",
      "['https://images-na.ssl-images-amazon.com/images/I/71flEJLrTCL._SY88.jpg']                                                                                                                                                                                                                                  1\n",
      "['https://images-na.ssl-images-amazon.com/images/I/71eJjyFC4HL._SY88.jpg']                                                                                                                                                                                                                                  1\n",
      "Name: image, Length: 6636, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'image'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: здесь в лучшем случае мы можем использовать количество картинок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### userid, itemid, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 127495, unique: 127448\n"
     ]
    }
   ],
   "source": [
    "print(f\"max: {df.userid.max()}, unique: {len(df.userid.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reviews_per_book = df.groupby( 'userid' ).userid.apply( lambda x: len( x ))\n",
    "# userid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 41319, unique: 41302\n"
     ]
    }
   ],
   "source": [
    "print(f\"max: {df.itemid.max()}, unique: {len(df.itemid.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти поля безусловно рассматриваем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field_name in ['userid', 'itemid', 'rating']:\n",
    "    selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем данные для построения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 718164 entries, 0 to 826894\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         718164 non-null  float64\n",
      " 1   verified        718164 non-null  bool   \n",
      " 2   reviewTime      718164 non-null  object \n",
      " 3   asin            718164 non-null  object \n",
      " 4   reviewerName    718024 non-null  object \n",
      " 5   reviewText      717907 non-null  object \n",
      " 6   summary         718008 non-null  object \n",
      " 7   unixReviewTime  718164 non-null  int64  \n",
      " 8   vote            93604 non-null   object \n",
      " 9   style           370202 non-null  object \n",
      " 10  image           4527 non-null    object \n",
      " 11  userid          718164 non-null  int64  \n",
      " 12  itemid          718164 non-null  int64  \n",
      " 13  rating          718164 non-null  float64\n",
      " 14  rating_check    718164 non-null  float64\n",
      "dtypes: bool(1), float64(3), int64(3), object(8)\n",
      "memory usage: 82.9+ MB\n"
     ]
    }
   ],
   "source": [
    "sdf = df[df.verified == True] # [list(selected_fields)]\n",
    "sdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 826895 entries, 0 to 826894\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         826895 non-null  float64\n",
      " 1   verified        826895 non-null  bool   \n",
      " 2   reviewTime      826895 non-null  object \n",
      " 3   asin            826895 non-null  object \n",
      " 4   reviewerName    826731 non-null  object \n",
      " 5   reviewText      826621 non-null  object \n",
      " 6   summary         826729 non-null  object \n",
      " 7   unixReviewTime  826895 non-null  int64  \n",
      " 8   vote            113951 non-null  object \n",
      " 9   style           428197 non-null  object \n",
      " 10  image           6979 non-null    object \n",
      " 11  userid          826895 non-null  int64  \n",
      " 12  itemid          826895 non-null  int64  \n",
      " 13  rating          826895 non-null  float64\n",
      "dtypes: bool(1), float64(2), int64(3), object(8)\n",
      "memory usage: 82.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 718164 entries, 0 to 826894\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         718164 non-null  float64\n",
      " 1   verified        718164 non-null  bool   \n",
      " 2   reviewTime      718164 non-null  object \n",
      " 3   asin            718164 non-null  object \n",
      " 4   reviewerName    718024 non-null  object \n",
      " 5   reviewText      717907 non-null  object \n",
      " 6   summary         718008 non-null  object \n",
      " 7   unixReviewTime  718164 non-null  int64  \n",
      " 8   vote            93604 non-null   object \n",
      " 9   style           370202 non-null  object \n",
      " 10  image           4527 non-null    object \n",
      " 11  userid          718164 non-null  int64  \n",
      " 12  itemid          718164 non-null  int64  \n",
      " 13  rating          718164 non-null  float64\n",
      " 14  rating_check    718164 non-null  float64\n",
      "dtypes: bool(1), float64(3), int64(3), object(8)\n",
      "memory usage: 82.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())\n",
    "print(sdf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_grocery_only = False\n",
    "use_verified_only = False\n",
    "if use_grocery_only:\n",
    "    df = train_grocery.copy()\n",
    "else:\n",
    "    df = train.copy()\n",
    "# print(df.verified.value_counts())\n",
    "if use_verified_only:\n",
    "    df = df[df.verified]\n",
    "train_data, test_data = train_test_split(df,random_state=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"rating\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 2\n",
      "------\n",
      "1.0    526498\n",
      "0.0     93673\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "describe(train_data, 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_coo = sparse.coo_matrix((train_data['rating'].astype(int),\n",
    "                                 (train_data['userid'],\n",
    "                                  train_data['itemid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(test_data.userid.values))\n",
    "# print(len(test_data.itemid.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import scipy.sparse as sparse\n",
    "# le = LabelEncoder()\n",
    "# le.fit(category.category)\n",
    "# category['category_code']=le.transform(category.category)\n",
    "# item_features  = sparse.coo_matrix(([1]*len(category),(category.itemid,category.category_code)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-407-2c6d3c29919d>:454: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['reviewCode'] = train_data.reviewText.apply(lambda x: fix_reviewText(x))\n",
      "<ipython-input-407-2c6d3c29919d>:455: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[\"reviewCodeRating\"] = train_data.reviewCode.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good             292551\n",
      "ok                98357\n",
      "love              72323\n",
      "great             62880\n",
      "delicious         29405\n",
      "excellent         19376\n",
      "favorite          16912\n",
      "yummy             15524\n",
      "nice               7266\n",
      "bad                2366\n",
      "perfect            2185\n",
      "so bad              360\n",
      "fresh               319\n",
      "expensive            82\n",
      "too expensive        51\n",
      "Name: reviewCode, dtype: int64 4    398493\n",
      "5    218605\n",
      "1      2417\n",
      "0       360\n",
      "3       214\n",
      "2        82\n",
      "Name: reviewCodeRating, dtype: int64 0.8    398493\n",
      "1.0    218605\n",
      "0.2      2417\n",
      "0.0       360\n",
      "0.6       214\n",
      "0.4        82\n",
      "Name: reviewCodeRatingNormalized, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-407-2c6d3c29919d>:457: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[\"reviewCodeRatingNormalized\"] = train_data.reviewCodeRating.apply(\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.sparse as sparse\n",
    "use_item_features = True\n",
    "# if use_item_features:\n",
    "#     train_df= train_data.copy()\n",
    "#     train_df = train_df[train_df.itemid.isin(category.itemid)]\n",
    "#     train_df =train_df.drop(['overall', 'verified', 'reviewTime', 'asin', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote', 'style', 'image'], axis=1)\n",
    "#     le = LabelEncoder()\n",
    "#     le.fit(category.category)\n",
    "#     category['category_code']=le.transform(category.category)\n",
    "#     train_df =train_df.merge(category, on='itemid')\n",
    "#     category_new= train_df.drop(['userid', 'rating', 'category'], axis=1)\n",
    "#     item_features  = sparse.coo_matrix(([1]*len(train_df),(category_new.itemid,category_new.category_code)))\n",
    "#     ratings_coo = sparse.coo_matrix((train_df['rating'].astype(int),\n",
    "#                                  (train_df['userid'],\n",
    "#                                   train_df['itemid'])))\n",
    "def fix_reviewText(x):\n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "    x = x.replace('delicious!', 'delicious')\n",
    "    x = x.replace('great!', 'great')\n",
    "    x = x.replace('yummy!', 'yummy')\n",
    "    x = x.replace('great product!', 'great product')\n",
    "    x = x.replace('yum!', 'yummy')\n",
    "    x = x.replace('great product.', 'great product')\n",
    "    x = x.replace('very good.', 'very good')\n",
    "    x = x.replace('good product.', 'good product')\n",
    "    x = x.replace('love it!', 'love it')\n",
    "    x = x.replace('delicious.', 'delicious')\n",
    "    x = x.replace('love it.', 'love it')\n",
    "    x = x.replace('very good!', 'very good')\n",
    "    x = x.replace('yum', 'yummy')\n",
    "    x = x.replace('as advertised', 'good')\n",
    "    x = x.replace('as expected', 'good')\n",
    "    x = x.replace('as described', 'delicious')\n",
    "    x = x.replace('yummymymymymy', 'yummy')\n",
    "    x = x.replace('yummymymymy', 'yummy')\n",
    "    x = x.replace('tasty', 'yummy')\n",
    "    if 'good' in x:\n",
    "        return 'good'\n",
    "    if 'love' in x:\n",
    "        return 'love'\n",
    "    if 'great' in x:\n",
    "        return 'great'\n",
    "    if 'delicious' in x:\n",
    "        return 'delicious'\n",
    "    if 'favorite' in x:\n",
    "        return 'favorite'\n",
    "    if 'excellent' in x:\n",
    "        return 'excellent'\n",
    "    if 'like' in x:\n",
    "        return 'ok'\n",
    "    if ':)' in x:\n",
    "        return 'ok'\n",
    "    if 'tasty' in x:\n",
    "        return 'tasty'\n",
    "    if 'ok' in x:\n",
    "        return 'ok'\n",
    "    if 'yummymy' in x:\n",
    "        return 'yummy'\n",
    "    if 'thank' in x:\n",
    "        return 'ok'\n",
    "    if 'a+' in x:\n",
    "        return 'excellent'\n",
    "    if 'yummy' in x:\n",
    "        return 'yummy'\n",
    "    if 'best' in x:\n",
    "        return 'excellent'\n",
    "    if 'awesome' in x:\n",
    "        return 'perfect'\n",
    "    if 'nice' in x:\n",
    "        return 'nice'\n",
    "    if 'a' in x:\n",
    "        return 'good'\n",
    "    if 'gift' in x:\n",
    "        return 'favorite'\n",
    "    if 'satisfied' in x:\n",
    "        return 'excellent'\n",
    "    if 'not bad' in x:\n",
    "        return 'ok'\n",
    "    if 'no problems' in x:\n",
    "        return 'ok'\n",
    "    if 'fine' in x:\n",
    "        return 'excellent'\n",
    "    if 'no comment' in x:\n",
    "        return 'bad'\n",
    "    if 'amazing' in x:\n",
    "        return 'favorite'\n",
    "    if 'pleased' in x:\n",
    "        return 'ok'\n",
    "    if 'stale' in x:\n",
    "        return 'bad'\n",
    "    if 'yuck' in x:\n",
    "        return 'bad'\n",
    "    if 'too sweet' in x:\n",
    "        return 'ok'\n",
    "    if 'wanted' in x:\n",
    "        return 'favorite'\n",
    "    if 'wonderful' in x:\n",
    "        return 'excellent'\n",
    "    if 'delish' in x:\n",
    "        return 'delicious'\n",
    "    if 'ty' in x:\n",
    "        return 'ok'\n",
    "    if 'super' in x:\n",
    "        return 'excellent'\n",
    "    if 'none' in x:\n",
    "        return 'bad'\n",
    "    if 'meh' in x:\n",
    "        return 'bad'\n",
    "    if 'k' in x:\n",
    "        return 'ok'\n",
    "    if 'no' in x:\n",
    "        return 'bad'\n",
    "    if 'works well' in x:\n",
    "        return 'good'\n",
    "    if '1' in x:\n",
    "        return 'so bad'\n",
    "    if 'no issues' in x:\n",
    "        return 'so bad'\n",
    "    if 'yuk' in x:\n",
    "        return 'so bad'\n",
    "    if 'excelent' in x:\n",
    "        return 'excellent'\n",
    "    if 'yes' in x:\n",
    "        return 'ok'\n",
    "    if 'sweet' in x:\n",
    "        return 'love'\n",
    "    if 'cool' in x:\n",
    "        return 'excellent'\n",
    "    if 'works' in x:\n",
    "        return 'ok'\n",
    "    if 'excelente' in x:\n",
    "        return 'excellent'\n",
    "    if 'superb' in x:\n",
    "        return 'excellent'\n",
    "    if 'wow' in x:\n",
    "        return 'great'\n",
    "    if 'enjoyed' in x:\n",
    "        return 'favorite'\n",
    "    if 'gross' in x:\n",
    "        return 'bad'\n",
    "    if 'not for me' in x:\n",
    "        return 'not for me'\n",
    "    if 'it works' in x:\n",
    "        return 'ok'\n",
    "    if 'mmmm' in x:\n",
    "        return 'great'\n",
    "    if 'mmmmm' in x:\n",
    "        return 'great'\n",
    "    if 'mmmmmm' in x:\n",
    "        return 'great'\n",
    "    if 'so so' in x:\n",
    "        return 'ok'\n",
    "    if 'thx' in x:\n",
    "        return 'ok'\n",
    "    if 'overpriced' in x:\n",
    "        return 'too expensive'\n",
    "    if '10/10' in x:\n",
    "        return 'excellent'\n",
    "    if ':-)' in x:\n",
    "        return 'ok'\n",
    "    if 'refreshing' in x:\n",
    "        return 'delicious'\n",
    "    if 'well done' in x:\n",
    "        return 'excellent'\n",
    "    if 'terrific' in x:\n",
    "        return 'excellent'\n",
    "    if 'fresh' in x:\n",
    "        return 'fresh'\n",
    "    if 'perfect' in x:\n",
    "        return 'perfect'\n",
    "    if 'food' in x:\n",
    "        return 'delicious'\n",
    "    if 'recommended' in x:\n",
    "        return 'love'\n",
    "    if 'delicous' in x:\n",
    "        return 'delicious'\n",
    "    if 'fun' in x:\n",
    "        return 'nice'\n",
    "    if 'exellent' in x:\n",
    "        return 'excellent'\n",
    "    if 'bye' in x:\n",
    "        return 'bad'\n",
    "    if 'luv it' in x:\n",
    "        return 'love'\n",
    "    if \"it's the cops!!!\" in x:\n",
    "        return 'lol'\n",
    "    if 'convenient' in x:\n",
    "        return 'ok'\n",
    "    if 'dry' in x:\n",
    "        return 'bad'\n",
    "    if 'gone' in x:\n",
    "        return 'so bad'\n",
    "    if 'horrible' in x:\n",
    "        return 'so bad'\n",
    "    if 'eh' in x:\n",
    "        return 'bad'\n",
    "    if 'enjoy' in x:\n",
    "        return 'favorite'\n",
    "    if 'highly recommend' in x:\n",
    "        return 'excellent'\n",
    "    if 'delicioso' in x:\n",
    "        return 'delicious'\n",
    "    if 'pricey' in x:\n",
    "        return 'expensive'\n",
    "    if 'bien' in x:\n",
    "        return 'ok'\n",
    "    if 'nummy' in x:\n",
    "        return 'yummy'\n",
    "    if 'bitter' in x:\n",
    "        return 'bad'\n",
    "    if 'will reorder' in x:\n",
    "        return 'ok'\n",
    "    if 'goood' in x:\n",
    "        return 'good'\n",
    "    if 'does the job' in x:\n",
    "        return 'ok'\n",
    "    if 'over priced' in x:\n",
    "        return 'too expensive'\n",
    "    if 'hot' in x:\n",
    "        return 'great'\n",
    "    if 'highly recomend' in x:\n",
    "        return 'excellent'\n",
    "    if 'thumbs up' in x:\n",
    "        return 'good'\n",
    "    if 'terrible' in x:\n",
    "        return 'so bad'\n",
    "    if 'different' in x:\n",
    "        return 'bad'\n",
    "    if 'strong' in x:\n",
    "        return 'good'\n",
    "    if 'yep' in x:\n",
    "        return 'ok'\n",
    "    if '4' in x:\n",
    "        return 'great'\n",
    "    if 'delightful' in x:\n",
    "        return 'excellent'\n",
    "    if 'just right' in x:\n",
    "        return 'good'\n",
    "    if 'disgusting' in x:\n",
    "        return 'so bad'\n",
    "    if 'fyi' in x:\n",
    "        return 'ok'\n",
    "    if 'smooth' in x:\n",
    "        return 'good'\n",
    "    if 'got it' in x:\n",
    "        return 'ok'\n",
    "    if 'd' in x:\n",
    "        return 'delicious'\n",
    "    if 'new' in x:\n",
    "        return 'ok'\n",
    "    if 'exelente' in x:\n",
    "        return 'excellent'\n",
    "    if 'so-so' in x:\n",
    "        return 'ok'\n",
    "    if 'luv these' in x:\n",
    "        return 'love'\n",
    "    if 'interesting' in x:\n",
    "        return 'favorite'\n",
    "    if 'decent' in x:\n",
    "        return 'great'\n",
    "    if 'too strong' in x:\n",
    "        return 'excellent'\n",
    "    if 'everything went very well' in x:\n",
    "        return 'excellent'\n",
    "    if 'goog' in x:\n",
    "        return 'good'\n",
    "    if 'worth every penny' in x:\n",
    "        return 'favorite'\n",
    "    if 'potent!' in x:\n",
    "        return 'great'\n",
    "    if 'go trump' in x:\n",
    "        return 'great'\n",
    "    if 'chewy' in x:\n",
    "        return 'yummy'\n",
    "    if 'coffee' in x:\n",
    "        return 'yummy'\n",
    "    if 'exelent' in x:\n",
    "        return 'excellent'\n",
    "    if 'very expensive' in x:\n",
    "        return 'too expensive'\n",
    "    if 'coffee' in x:\n",
    "        return 'yummy'\n",
    "    if 'go trump' in x:\n",
    "        return 'great'\n",
    "    if 'chewy' in x:\n",
    "        return 'yummy'\n",
    "    if \"it's coffee\" in x:\n",
    "        return 'yummy'\n",
    "    if 'spicy!' in x:\n",
    "        return 'yummy'\n",
    "    if 'crunchy' in x:\n",
    "        return 'yummy'\n",
    "    if 'cute' in x:\n",
    "        return 'ok'\n",
    "    if 'f' in x:\n",
    "        return 'bad'\n",
    "    if 'pricy' in x:\n",
    "        return 'expensive'\n",
    "    if '5 out of 5' in x:\n",
    "        return 'excellent'\n",
    "    if 'to expensive' in x:\n",
    "        return 'too expensive'\n",
    "    if 'c' in x:\n",
    "        return 'ok'\n",
    "    if 'worth the price' in x:\n",
    "        return 'good'\n",
    "    if 'soso' in x:\n",
    "        return 'ok'\n",
    "    if 'rip off' in x:\n",
    "        return 'so bad'\n",
    "    if 'live it' in x:\n",
    "        return 'love'\n",
    "    if '=)' in x:\n",
    "        return 'ok'\n",
    "    if 'gr8' in x:\n",
    "        return 'great'\n",
    "    if 'everything went well' in x:\n",
    "        return 'favorite'\n",
    "    if 'worth it' in x:\n",
    "        return 'good'\n",
    "    if 'for my son' in x:\n",
    "        return 'ok'\n",
    "    if 'price' in x:\n",
    "        return 'expensive'\n",
    "    if 'expensive but worth it' in x:\n",
    "        return 'expensive'\n",
    "    if 'groovy' in x:\n",
    "        return 'ok'\n",
    "    if 'get some' in x:\n",
    "        return 'bad'\n",
    "    if \"worth buying\" in x:\n",
    "        return 'great'\n",
    "    if 'exccelent' in x:\n",
    "        return 'excellent'\n",
    "    if 'spicy' in x:\n",
    "        return 'yummy'\n",
    "    if 'price bit high' in x:\n",
    "        return 'expensive'\n",
    "    if 'cheese' in x:\n",
    "        return 'yummy'\n",
    "    if 'worth it!' in x:\n",
    "        return 'ok'\n",
    "    if 'b+' in x:\n",
    "        return 'good'\n",
    "    if 'b' in x:\n",
    "        return 'good'\n",
    "    if 'price is right' in x:\n",
    "        return 'ok'\n",
    "    if 'ugh' in x:\n",
    "        return 'bad'\n",
    "    if 'ugh!' in x:\n",
    "        return 'bad'\n",
    "    if 'will buy more' in x:\n",
    "        return 'great'\n",
    "    if '<3' in x:\n",
    "        return 'love'\n",
    "    if 'very spicy' in x:\n",
    "        return 'yummy'\n",
    "    if 'poor' in x:\n",
    "        return 'bad'\n",
    "    if 'nuts' in x:\n",
    "        return 'yummy'\n",
    "    if 'very positive' in x:\n",
    "        return 'great'\n",
    "    if 'expensive!' in x:\n",
    "        return 'too expensive'\n",
    "    if 'use this on everything' in x:\n",
    "        return 'great'\n",
    "    if ';-)' in x:\n",
    "        return 'ok'\n",
    "    if ';)' in x:\n",
    "        return 'ok'\n",
    "    if 'eww' in x:\n",
    "        return 'ok'\n",
    "    if 'well worth the money' in x:\n",
    "        return 'great'\n",
    "    if 'gorgeous!' in x:\n",
    "        return 'love'\n",
    "    if ': )' in x:\n",
    "        return 'ok'\n",
    "    if 'so, so ' in x:\n",
    "        return 'ok'\n",
    "    if 'soothing' in x:\n",
    "        return 'favorite'\n",
    "    if 'yup' in x:\n",
    "        return 'ok'\n",
    "    if 'yuumy' in x:\n",
    "        return 'yummy'\n",
    "    if 'ripe' in x:\n",
    "        return 'ok'\n",
    "    if 'hulls!' in x:\n",
    "        return 'so bad'\n",
    "    if 'vg' in x:\n",
    "        return 'great'\n",
    "    if 'very thin' in x:\n",
    "        return 'bad'\n",
    "    if \"nutritious\" in x:\n",
    "        return 'yummy'\n",
    "    if 'very sour' in x:\n",
    "        return 'bad'\n",
    "    if 'riquisimos' in x:\n",
    "        return 'yummy'\n",
    "    if 'help' in x:\n",
    "        return 'bad'\n",
    "    if 'its soup' in x:\n",
    "        return 'yummy'\n",
    "    if 'pepper' in x:\n",
    "        return 'yummy'\n",
    "    if 'potent' in x:\n",
    "        return 'great'\n",
    "    if 'too expensive!' in x:\n",
    "        return 'too expensive'\n",
    "    if 'price is right' in x:\n",
    "        return 'ok'\n",
    "    if 'very goo' in x:\n",
    "        return 'great'\n",
    "    if 'very' in x:\n",
    "        return 'good'\n",
    "    if 'just the right size' in x:\n",
    "        return 'great'\n",
    "    if 'too thin' in x:\n",
    "        return 'bad'\n",
    "    if 'use it on everything' in x:\n",
    "        return 'good'\n",
    "    if 'umm!!' in x:\n",
    "        return 'yummy'\n",
    "    if 'umm' in x:\n",
    "        return 'yummy'\n",
    "    if '5' in x:\n",
    "        return 'excellent'\n",
    "    if x != 'good' or 'love' or 'great' or 'ok' or 'excellent' or 'delicious' or 'yummy' or 'favorite' or 'nice' or 'perfect' or 'fresh' or 'too expensive' or 'expensive' or 'bad' or 'lol' in x:\n",
    "        return 'ok'\n",
    "    return x\n",
    "review_code_rating_dict = {\n",
    "    \"good\": 4,\n",
    "    \"ok\": 4,\n",
    "    \"love\": 5,\n",
    "    \"great\": 5,\n",
    "    \"delicious\": 5,\n",
    "    \"excellent\": 5,\n",
    "    \"favorite\": 5,\n",
    "    \"yummy\": 5,\n",
    "    \"nice\": 4,\n",
    "    \"bad\": 1,\n",
    "    \"perfect\": 5,\n",
    "    \"so bad\": 0,\n",
    "    \"fresh\": 4,\n",
    "    \"expensive\": 2,\n",
    "    \"too expensive\": 1,\n",
    "}\n",
    "if use_item_features:\n",
    "    train_data['reviewCode'] = train_data.reviewText.apply(lambda x: fix_reviewText(x))\n",
    "    train_data[\"reviewCodeRating\"] = train_data.reviewCode.apply(\n",
    "        lambda x: 3 if x not in review_code_rating_dict else review_code_rating_dict[x])\n",
    "    train_data[\"reviewCodeRatingNormalized\"] = train_data.reviewCodeRating.apply(\n",
    "        lambda x: x / 5)\n",
    "    print(\n",
    "        train_data.reviewCode.value_counts(), \n",
    "        train_data[\"reviewCodeRating\"].value_counts(), \n",
    "        train_data[\"reviewCodeRatingNormalized\"].value_counts())  \n",
    "    item_features = sparse.coo_matrix(\n",
    "        (train_data['reviewCodeRatingNormalized'],\n",
    "        (train_data['userid'], train_data['itemid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим модель и считаем roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for no_components=30, learning_rate=0.1, epochs=30 . . .\n",
      "206724 206724\n",
      "8.9s, roc_auc_score: 0.63085\n"
     ]
    }
   ],
   "source": [
    "NUM_THREADS = 4 #число потоков\n",
    "\n",
    "model_prev = None\n",
    "no_components_prev = None\n",
    "learning_rate_prev = None\n",
    "\n",
    "def get_model(no_components, learning_rate):\n",
    "    global model_prev, no_components_prev, learning_rate_prev\n",
    "    model = model_prev if model_prev is not None and no_components_prev == no_components else LightFM(loss='logistic',learning_rate=learning_rate, no_components=no_components)\n",
    "    model_prev = model  \n",
    "    learning_rate_prev = learning_rate\n",
    "    no_components_prev = no_components\n",
    "    return model\n",
    "\n",
    "def fit_model(no_components, learning_rate, epochs):\n",
    "    model = get_model(no_components, learning_rate)\n",
    "    if not use_item_features:\n",
    "        model = model.fit(ratings_coo, epochs=epochs, num_threads=NUM_THREADS)\n",
    "    else:\n",
    "        model = model.fit(ratings_coo, epochs=epochs, num_threads=NUM_THREADS,item_features=item_features)\n",
    "    return model\n",
    "\n",
    "def get_roc_auc_score(params):   \n",
    "    no_components = params[\"no_components\"][\"actual\"]\n",
    "    learning_rate = params[\"learning_rate\"][\"actual\"]\n",
    "    learning_rate_round = params[\"learning_rate\"][\"round\"]\n",
    "    epochs = params[\"epochs\"][\"actual\"]\n",
    "    print(f\"model for no_components={no_components}, learning_rate={round(learning_rate, learning_rate_round)}, epochs={epochs} . . .\")\n",
    "    import time\n",
    "    start = time.time()\n",
    "    model = fit_model(no_components, learning_rate, epochs)\n",
    "    print(len(test_data.userid.values), len(test_data.itemid.values))\n",
    "    preds = model.predict(test_data.userid.values, test_data.itemid.values)\n",
    "    roc_auc_score = sklearn.metrics.roc_auc_score(test_data.rating, preds)\n",
    "    print(f\"{round(time.time() - start, 1)}s, roc_auc_score: {round(roc_auc_score, 5)}\")\n",
    "    return roc_auc_score\n",
    "    \n",
    "no_components = 30\n",
    "learning_rate = 0.1\n",
    "epochs = 30\n",
    "params = {\n",
    "    \"no_components\": {\n",
    "        \"actual\": 30,\n",
    "    },\n",
    "    \"learning_rate\": {\n",
    "        \"actual\": 0.1,\n",
    "        \"round\": 3,\n",
    "    },\n",
    "    \"epochs\": {\n",
    "        \"actual\": 30,\n",
    "    },\n",
    "}\n",
    "roc_auc_score = get_roc_auc_score(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Подберем гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start . . .\n",
      "model for no_components=1, learning_rate=0.1, epochs=8 . . .\n",
      "206724 206724\n",
      "0.7s, roc_auc_score: 0.64429\n",
      "model for no_components=128, learning_rate=0.1, epochs=1 . . .\n",
      "206724 206724\n",
      "1.3s, roc_auc_score: 0.59731\n",
      "model for no_components=1, learning_rate=0.2, epochs=1 . . .\n",
      "206724 206724\n",
      "0.1s, roc_auc_score: 0.61553\n",
      "roc_auc: 0.64429, delta: 0.64429 for epochs: 8/8, no_components: 1/128, learning_rate: 0.1/0.1\n",
      "model for no_components=1, learning_rate=0.1, epochs=16 . . .\n",
      "206724 206724\n",
      "1.3s, roc_auc_score: 0.64312\n",
      "model for no_components=128, learning_rate=0.1, epochs=8 . . .\n",
      "206724 206724\n",
      "8.1s, roc_auc_score: 0.63483\n",
      "model for no_components=1, learning_rate=0.2, epochs=8 . . .\n",
      "206724 206724\n",
      "0.7s, roc_auc_score: 0.64116\n",
      "no_components_step: -64\n",
      "model for no_components=1, learning_rate=0.1, epochs=16 . . .\n",
      "206724 206724\n",
      "1.3s, roc_auc_score: 0.6378\n",
      "model for no_components=-64, learning_rate=0.1, epochs=8 . . .\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-409-1ba02b36ede1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mupdate_actual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"actual\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"roc_auc_delta\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"roc_auc_delta\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"roc_auc_delta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-408-c30e8b024b18>\u001b[0m in \u001b[0;36mget_roc_auc_score\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-408-c30e8b024b18>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(no_components, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_item_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_coo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_THREADS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-408-c30e8b024b18>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(no_components, learning_rate)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mmodel_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_components_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_prev\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel_prev\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_components_prev\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mno_components\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mLightFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlearning_rate_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, no_components, k, n, learning_schedule, loss, learning_rate, rho, epsilon, item_alpha, user_alpha, max_sampled, random_state)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mitem_alpha\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0muser_alpha\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mno_components\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_actual():\n",
    "    global no_components_min, no_components, epochs_min, epochs, learning_rate_min, learning_rate\n",
    "    no_components_actual = no_components_min if no_components < no_components_min else no_components\n",
    "    epochs_actual = epochs_min if epochs < epochs_min else epochs\n",
    "    learning_rate_actual = learning_rate_min if learning_rate < learning_rate_min else learning_rate\n",
    "    return no_components_actual, learning_rate_actual, epochs_actual\n",
    "    \n",
    "params = {\n",
    "    \"epochs\": {\n",
    "        \"val\": 0,\n",
    "        \"min\": 1,\n",
    "        \"step\": 8,\n",
    "        \"step_min_abs\": 1,\n",
    "        \"round\": 0,  \n",
    "    },\n",
    "    \"no_components\": {\n",
    "        \"val\": 0,\n",
    "        \"min\": 1,\n",
    "        \"step\": 128,\n",
    "        \"step_min_abs\": 1,\n",
    "        \"round\": 0,  \n",
    "    },\n",
    "    \"learning_rate\": {\n",
    "        \"val\": 0.1,\n",
    "        \"min\": 0.005,\n",
    "        \"step\": 0.1,\n",
    "        \"step_min_abs\": 0.005,\n",
    "        \"round\": 3,\n",
    "    },\n",
    "}\n",
    "        \n",
    "def update_actual():\n",
    "    global params\n",
    "    for k, v in params.items():\n",
    "        v[\"actual\"] = v[\"min\"] if v[\"val\"] < v[\"min\"] else v[\"val\"]\n",
    "        \n",
    "def stat():\n",
    "    global params\n",
    "    s = ''\n",
    "    update_actual()\n",
    "    for k, v in params.items():\n",
    "        if len(s) > 0:\n",
    "            s = s + \", \"\n",
    "        s = s + f'{k}: {v[\"actual\"]}/{v[\"step\"]}'\n",
    "    return s\n",
    "\n",
    "\n",
    "delta_min = 0.00001\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "print(\"Start . . .\")\n",
    "roc_auc = 0\n",
    "import math\n",
    "while True: \n",
    "    for k, v in params.items():\n",
    "        v[\"roc_auc_delta\"] = 0 \n",
    "\n",
    "    delta = 0\n",
    "    delta_neg = 0\n",
    "    for k, v in params.items():\n",
    "        if abs(v[\"step\"]) >= v[\"step_min_abs\"]:\n",
    "            update_actual()\n",
    "            v[\"actual\"] = v[\"val\"] + v[\"step\"]\n",
    "            v[\"roc_auc_delta\"] = get_roc_auc_score(params) - roc_auc\n",
    "            if v[\"roc_auc_delta\"] > delta:\n",
    "                delta = v[\"roc_auc_delta\"]\n",
    "            elif v[\"roc_auc_delta\"] < delta_neg:\n",
    "                delta_neg = v[\"roc_auc_delta\"]\n",
    "\n",
    "    if delta >= delta_min:\n",
    "        for k, v in params.items():\n",
    "            if v[\"roc_auc_delta\"] >= delta:\n",
    "                v[\"val\"] = v[\"val\"] + v[\"step\"]\n",
    "        roc_auc = roc_auc + delta\n",
    "        \n",
    "        print(f\"roc_auc: {round(roc_auc, 5)}, delta: {round(delta, 5)} for {stat()}\")   \n",
    "    else:\n",
    "        need_stop_by_min_abs = True\n",
    "        for k, v in params.items():\n",
    "            if abs(v[\"step\"]) > v[\"step_min_abs\"]:\n",
    "                need_stop_by_min_abs = False\n",
    "                break\n",
    "        if need_stop_by_min_abs:\n",
    "            print(\"Stopped by step_min_abs\")\n",
    "            break \n",
    "        elif -delta_neg < delta_min:\n",
    "            print(f\"Stopped by delta_min: -delta_neg={-delta_neg}\")\n",
    "            break\n",
    "        else:\n",
    "            did_change_step = False\n",
    "            for k, v in params.items():\n",
    "                if abs(v[\"step\"]) > v[\"step_min_abs\"] and v[\"roc_auc_delta\"] <= delta_neg:\n",
    "                    v[\"step\"] = -round(math.copysign(abs(v[\"step\"])/2, v[\"step\"]), v[\"round\"])\n",
    "                    if v[\"round\"] == 0:\n",
    "                        v[\"step\"] = int(v[\"step\"])              \n",
    "                    print(f'{k}_step: {v[\"step\"]}')\n",
    "                    did_change_step = True\n",
    "                    break\n",
    "            if not did_change_step:\n",
    "                print(\"Stopped by step_min_abs\")\n",
    "                break\n",
    "            \n",
    "print(f\"{round(time.time() - start, 1)}s, Ready: roc_auc={round(roc_auc, 5)} for {stat()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим модель с подобранными гиперпараметрами, считаем roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.73293 for epochs: 3/-1, no_components: 256/128, learning_rate: 0.5/0.1\n"
     ]
    }
   ],
   "source": [
    "update_actual()\n",
    "no_components = params[\"no_components\"][\"actual\"]\n",
    "learning_rate = params[\"learning_rate\"][\"actual\"]\n",
    "epochs = params[\"epochs\"][\"actual\"]\n",
    "\n",
    "# для всего train'а:\n",
    "# no_components = 128\n",
    "# epochs = 7\n",
    "# learning_rate = 0.225\n",
    "\n",
    "# для verified его части:\n",
    "# no_components = 128\n",
    "# epochs = 10\n",
    "# learning_rate = 0.187\n",
    "\n",
    "# для verified его части (другой вариант):\n",
    "# no_components = 128\n",
    "# epochs = 6\n",
    "# learning_rate = 0.275\n",
    "\n",
    "model = fit_model(no_components, learning_rate, epochs)\n",
    "preds = model.predict(test_data.userid.values, test_data.itemid.values)\n",
    "roc_auc_score = sklearn.metrics.roc_auc_score(test_data.rating,preds)\n",
    "print(f'roc_auc_score: {round(roc_auc_score, 5)} for {stat()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-29.024730682373047, 34.247283935546875)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test.userid.values, test.itemid.values)\n",
    "preds.min(), preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_preds = (preds - preds.min())/(preds - preds.min()).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_preds.min(), normalized_preds.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49339664, 0.48330563, 0.46831298, ..., 0.46867513, 0.5053303 ,\n",
       "       0.50860132])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['rating'] = normalized_preds\n",
    "submission.to_csv('submission_fm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUNDED вариант ухудшает результат: 0.51975 против 0.73149\n",
    "# submission['rating'] = list(map(lambda x: round(x), normalized_preds))\n",
    "# submission.to_csv('submission_fm_rounded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l2: 0.12065\tvalid_0's l1: 0.242037\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l2: 0.120604\tvalid_0's l1: 0.242046\n",
      "[3]\tvalid_0's l2: 0.120558\tvalid_0's l1: 0.242022\n",
      "[4]\tvalid_0's l2: 0.120541\tvalid_0's l1: 0.242005\n",
      "[5]\tvalid_0's l2: 0.120516\tvalid_0's l1: 0.241981\n",
      "[6]\tvalid_0's l2: 0.120501\tvalid_0's l1: 0.241695\n",
      "[7]\tvalid_0's l2: 0.120498\tvalid_0's l1: 0.241522\n",
      "[8]\tvalid_0's l2: 0.120482\tvalid_0's l1: 0.2414\n",
      "[9]\tvalid_0's l2: 0.120465\tvalid_0's l1: 0.241321\n",
      "[10]\tvalid_0's l2: 0.120451\tvalid_0's l1: 0.241266\n",
      "[11]\tvalid_0's l2: 0.120447\tvalid_0's l1: 0.241195\n",
      "[12]\tvalid_0's l2: 0.120444\tvalid_0's l1: 0.241146\n",
      "[13]\tvalid_0's l2: 0.120442\tvalid_0's l1: 0.241115\n",
      "[14]\tvalid_0's l2: 0.120445\tvalid_0's l1: 0.241103\n",
      "[15]\tvalid_0's l2: 0.12042\tvalid_0's l1: 0.241068\n",
      "[16]\tvalid_0's l2: 0.120415\tvalid_0's l1: 0.241167\n",
      "[17]\tvalid_0's l2: 0.120401\tvalid_0's l1: 0.241202\n",
      "[18]\tvalid_0's l2: 0.120402\tvalid_0's l1: 0.241234\n",
      "[19]\tvalid_0's l2: 0.120397\tvalid_0's l1: 0.24124\n",
      "[20]\tvalid_0's l2: 0.120388\tvalid_0's l1: 0.241233\n",
      "[21]\tvalid_0's l2: 0.120385\tvalid_0's l1: 0.241171\n",
      "[22]\tvalid_0's l2: 0.120375\tvalid_0's l1: 0.241122\n",
      "[23]\tvalid_0's l2: 0.120368\tvalid_0's l1: 0.241094\n",
      "[24]\tvalid_0's l2: 0.120362\tvalid_0's l1: 0.241065\n",
      "[25]\tvalid_0's l2: 0.12035\tvalid_0's l1: 0.241035\n",
      "[26]\tvalid_0's l2: 0.120346\tvalid_0's l1: 0.241157\n",
      "[27]\tvalid_0's l2: 0.120337\tvalid_0's l1: 0.241222\n",
      "[28]\tvalid_0's l2: 0.120333\tvalid_0's l1: 0.241264\n",
      "[29]\tvalid_0's l2: 0.120332\tvalid_0's l1: 0.241289\n",
      "[30]\tvalid_0's l2: 0.120333\tvalid_0's l1: 0.241298\n",
      "[31]\tvalid_0's l2: 0.120329\tvalid_0's l1: 0.241307\n",
      "[32]\tvalid_0's l2: 0.120322\tvalid_0's l1: 0.2413\n",
      "[33]\tvalid_0's l2: 0.120321\tvalid_0's l1: 0.241307\n",
      "[34]\tvalid_0's l2: 0.120324\tvalid_0's l1: 0.241306\n",
      "[35]\tvalid_0's l2: 0.12032\tvalid_0's l1: 0.241298\n",
      "[36]\tvalid_0's l2: 0.120317\tvalid_0's l1: 0.241265\n",
      "[37]\tvalid_0's l2: 0.120309\tvalid_0's l1: 0.241247\n",
      "[38]\tvalid_0's l2: 0.120308\tvalid_0's l1: 0.241229\n",
      "[39]\tvalid_0's l2: 0.120302\tvalid_0's l1: 0.241213\n",
      "[40]\tvalid_0's l2: 0.120293\tvalid_0's l1: 0.241203\n",
      "[41]\tvalid_0's l2: 0.120295\tvalid_0's l1: 0.241265\n",
      "[42]\tvalid_0's l2: 0.120293\tvalid_0's l1: 0.241298\n",
      "[43]\tvalid_0's l2: 0.12029\tvalid_0's l1: 0.24131\n",
      "[44]\tvalid_0's l2: 0.120285\tvalid_0's l1: 0.24132\n",
      "[45]\tvalid_0's l2: 0.120287\tvalid_0's l1: 0.241325\n",
      "[46]\tvalid_0's l2: 0.120284\tvalid_0's l1: 0.241275\n",
      "[47]\tvalid_0's l2: 0.120285\tvalid_0's l1: 0.241244\n",
      "[48]\tvalid_0's l2: 0.120279\tvalid_0's l1: 0.241217\n",
      "[49]\tvalid_0's l2: 0.120274\tvalid_0's l1: 0.241201\n",
      "[50]\tvalid_0's l2: 0.120275\tvalid_0's l1: 0.24119\n",
      "[51]\tvalid_0's l2: 0.120274\tvalid_0's l1: 0.241256\n",
      "[52]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.241298\n",
      "[53]\tvalid_0's l2: 0.12027\tvalid_0's l1: 0.241321\n",
      "[54]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.241331\n",
      "[55]\tvalid_0's l2: 0.120274\tvalid_0's l1: 0.241339\n",
      "[56]\tvalid_0's l2: 0.120275\tvalid_0's l1: 0.24117\n",
      "[57]\tvalid_0's l2: 0.120274\tvalid_0's l1: 0.241065\n",
      "[58]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240993\n",
      "[59]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240954\n",
      "[60]\tvalid_0's l2: 0.120264\tvalid_0's l1: 0.24093\n",
      "[61]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240957\n",
      "[62]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.240971\n",
      "[63]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.24098\n",
      "[64]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240987\n",
      "[65]\tvalid_0's l2: 0.120265\tvalid_0's l1: 0.24099\n",
      "[66]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.240899\n",
      "[67]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240852\n",
      "[68]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240812\n",
      "[69]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.240791\n",
      "[70]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.240778\n",
      "[71]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240783\n",
      "[72]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240785\n",
      "[73]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.24078\n",
      "[74]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.240773\n",
      "[75]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.240772\n",
      "[76]\tvalid_0's l2: 0.120249\tvalid_0's l1: 0.240937\n",
      "[77]\tvalid_0's l2: 0.120247\tvalid_0's l1: 0.241041\n",
      "[78]\tvalid_0's l2: 0.120248\tvalid_0's l1: 0.241106\n",
      "[79]\tvalid_0's l2: 0.120251\tvalid_0's l1: 0.241141\n",
      "[80]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.241164\n",
      "[81]\tvalid_0's l2: 0.12025\tvalid_0's l1: 0.241103\n",
      "[82]\tvalid_0's l2: 0.120246\tvalid_0's l1: 0.241067\n",
      "[83]\tvalid_0's l2: 0.120246\tvalid_0's l1: 0.241039\n",
      "[84]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.241039\n",
      "[85]\tvalid_0's l2: 0.120254\tvalid_0's l1: 0.241022\n",
      "[86]\tvalid_0's l2: 0.120254\tvalid_0's l1: 0.241007\n",
      "[87]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.240994\n",
      "[88]\tvalid_0's l2: 0.120255\tvalid_0's l1: 0.240984\n",
      "[89]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.240974\n",
      "[90]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.240974\n",
      "[91]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.240906\n",
      "[92]\tvalid_0's l2: 0.120255\tvalid_0's l1: 0.240865\n",
      "[93]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240842\n",
      "[94]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240824\n",
      "[95]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240815\n",
      "[96]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.24095\n",
      "[97]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.241034\n",
      "[98]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.241086\n",
      "[99]\tvalid_0's l2: 0.120255\tvalid_0's l1: 0.241113\n",
      "[100]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.241125\n",
      "[101]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.241017\n",
      "[102]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240946\n",
      "[103]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.2409\n",
      "[104]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240876\n",
      "[105]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.240855\n",
      "[106]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240906\n",
      "[107]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240941\n",
      "[108]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240958\n",
      "[109]\tvalid_0's l2: 0.120264\tvalid_0's l1: 0.240971\n",
      "[110]\tvalid_0's l2: 0.120265\tvalid_0's l1: 0.240974\n",
      "[111]\tvalid_0's l2: 0.120264\tvalid_0's l1: 0.240832\n",
      "[112]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240748\n",
      "[113]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240694\n",
      "[114]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240668\n",
      "[115]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240639\n",
      "[116]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240683\n",
      "[117]\tvalid_0's l2: 0.120265\tvalid_0's l1: 0.240713\n",
      "[118]\tvalid_0's l2: 0.120264\tvalid_0's l1: 0.240729\n",
      "[119]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240738\n",
      "[120]\tvalid_0's l2: 0.120259\tvalid_0's l1: 0.240744\n",
      "[121]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240854\n",
      "[122]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240916\n",
      "[123]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240955\n",
      "[124]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240983\n",
      "[125]\tvalid_0's l2: 0.12026\tvalid_0's l1: 0.240995\n",
      "[126]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240921\n",
      "[127]\tvalid_0's l2: 0.120254\tvalid_0's l1: 0.240873\n",
      "[128]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240851\n",
      "[129]\tvalid_0's l2: 0.120259\tvalid_0's l1: 0.240837\n",
      "[130]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240832\n",
      "[131]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.240844\n",
      "[132]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.24085\n",
      "[133]\tvalid_0's l2: 0.12026\tvalid_0's l1: 0.240851\n",
      "[134]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240854\n",
      "[135]\tvalid_0's l2: 0.120265\tvalid_0's l1: 0.240862\n",
      "[136]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240808\n",
      "[137]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240774\n",
      "[138]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240754\n",
      "[139]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240742\n",
      "[140]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240733\n",
      "[141]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240723\n",
      "[142]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240723\n",
      "[143]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240722\n",
      "[144]\tvalid_0's l2: 0.120267\tvalid_0's l1: 0.240722\n",
      "[145]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240716\n",
      "[146]\tvalid_0's l2: 0.120267\tvalid_0's l1: 0.240843\n",
      "[147]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240915\n",
      "[148]\tvalid_0's l2: 0.12027\tvalid_0's l1: 0.240959\n",
      "[149]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240983\n",
      "[150]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.240998\n",
      "[151]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240975\n",
      "[152]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240961\n",
      "[153]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240958\n",
      "[154]\tvalid_0's l2: 0.120267\tvalid_0's l1: 0.240957\n",
      "[155]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240948\n",
      "[156]\tvalid_0's l2: 0.12026\tvalid_0's l1: 0.240908\n",
      "[157]\tvalid_0's l2: 0.120259\tvalid_0's l1: 0.240885\n",
      "[158]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.240875\n",
      "[159]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240865\n",
      "[160]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240859\n",
      "[161]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240779\n",
      "[162]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240702\n",
      "[164]\tvalid_0's l2: 0.120267\tvalid_0's l1: 0.240686\n",
      "[165]\tvalid_0's l2: 0.12027\tvalid_0's l1: 0.240683\n",
      "[166]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240765\n",
      "[167]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.240816\n",
      "[168]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240837\n",
      "[169]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240854\n",
      "[170]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.24086\n",
      "[171]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240879\n",
      "[172]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240892\n",
      "[173]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.240898\n",
      "[174]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240898\n",
      "[175]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240895\n",
      "[176]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240892\n",
      "[177]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240897\n",
      "[178]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240901\n",
      "[179]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.240898\n",
      "[180]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.2409\n",
      "[181]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240751\n",
      "[182]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.24066\n",
      "[183]\tvalid_0's l2: 0.12027\tvalid_0's l1: 0.240606\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's l2: 0.120246\tvalid_0's l1: 0.241039\n",
      "Starting predicting...\n",
      "The roc_auc_score of prediction is: 0.5526532642022016\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_data_GB = pd.DataFrame({\n",
    "    'userid': sdf['userid'],\n",
    "    'itemid': sdf['itemid'],\n",
    "    'rating': sdf['rating']\n",
    "})\n",
    "\n",
    "test_data_GB = pd.DataFrame({\n",
    "    'userid': test['userid'],\n",
    "    'itemid': test['itemid'],\n",
    "})\n",
    "train_data_GB_train, test_data_GB_test = train_test_split(train_data_GB,random_state=13, shuffle=True)\n",
    "y_train = train_data_GB_train['rating']\n",
    "y_test = test_data_GB_test['rating']\n",
    "X_train = train_data_GB_train.drop('rating', axis=1)\n",
    "X_test = test_data_GB_test.drop('rating', axis=1)\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 8,\n",
    "    'learning_rate': 0.4,\n",
    "    'feature_fraction': 0.1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=200,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=100)\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The roc_auc_score of prediction is:', sklearn.metrics.roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# y____ =  gbm.predict(test_data_GB, num_iteration=gbm.best_iteration)\n",
    "# c = (normalized_preds  + y____) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_gbm = gbm.predict(test_data_GB, num_iteration=gbm.best_iteration)\n",
    "preds_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['rating'] = c\n",
    "submission.to_csv('submission_gbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
