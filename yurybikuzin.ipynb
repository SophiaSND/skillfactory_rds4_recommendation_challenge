{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(df, field_name):\n",
    "    print(f\"Колонка \\\"{field_name}\\\":\")\n",
    "    print(\"------\")\n",
    "    print(\"na:\", df[field_name].isna().sum())\n",
    "    print(\"уникальных значений:\", len(df[field_name].unique()))\n",
    "    print(\"------\")\n",
    "    print(df[field_name].value_counts())  \n",
    "    \n",
    "def param_data(data): # посмотрим на данные\n",
    "    \"\"\"dataset required parameters \"\"\"\n",
    "    param = pd.DataFrame({\n",
    "              'dtypes': data.dtypes.values,\n",
    "              'nunique': data.nunique().values,\n",
    "              'isna': data.isna().sum().values,\n",
    "              'loc[0]': data.loc[0].values,\n",
    "              }, \n",
    "             index = data.loc[0].index)\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42003 entries, 0 to 42002\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   itemid       42003 non-null  int64 \n",
      " 1   brand        41574 non-null  object\n",
      " 2   description  38588 non-null  object\n",
      " 3   title        42003 non-null  object\n",
      " 4   main_cat     41920 non-null  object\n",
      " 5   price        25786 non-null  object\n",
      " 6   is_train     42003 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 2.0+ MB\n",
      "None    itemid                  brand  \\\n",
      "0       1                 Lipton   \n",
      "1       0                 Lipton   \n",
      "2       2            Organo Gold   \n",
      "3       3               Mae Ploy   \n",
      "4       4  Harold Import Company   \n",
      "\n",
      "                                         description  \\\n",
      "0  Lipton Yellow Label Tea use only the finest te...   \n",
      "1  Lipton Yellow Label Teabags uses a new way to ...   \n",
      "2  20 Sachets\\n\\nEmpty contents into cup\\nPour 8o...   \n",
      "3  Mae Ploy Thai green curry paste.\\n\\nIngredient...   \n",
      "4  This set is a great value from one of the grea...   \n",
      "\n",
      "                                               title     main_cat   price  \\\n",
      "0         Lipton Yellow Label Tea (loose tea) - 450g      Grocery  $12.46   \n",
      "1  Lipton Yellow Label Finest Blend Tea Bags 100 ...      Grocery  $12.98   \n",
      "2  Organo Gold Cafe Supreme 100% Certified Ganode...      Grocery  $29.90   \n",
      "3                  Mae Ploy Green Curry Paste, 14 oz      Grocery     NaN   \n",
      "4                  Ateco Food Coloring Kit, 6 colors  Amazon Home     NaN   \n",
      "\n",
      "   is_train  \n",
      "0      True  \n",
      "1      True  \n",
      "2      True  \n",
      "3      True  \n",
      "4      True  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 166917 entries, 0 to 166916\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   itemid    166917 non-null  int64 \n",
      " 1   category  166917 non-null  object\n",
      " 2   is_train  166917 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(1)\n",
      "memory usage: 2.7+ MB\n",
      "None    itemid                category  is_train\n",
      "0       1  Grocery & Gourmet Food      True\n",
      "1       1               Beverages      True\n",
      "2       1     Coffee, Tea & Cocoa      True\n",
      "3       1                     Tea      True\n",
      "4       1                   Black      True\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178606 entries, 0 to 178605\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count   Dtype\n",
      "---  ------            --------------   -----\n",
      " 0   itemid            178606 non-null  int64\n",
      " 1   also_view_itemid  178606 non-null  int64\n",
      " 2   is_train          178606 non-null  bool \n",
      "dtypes: bool(1), int64(2)\n",
      "memory usage: 2.9 MB\n",
      "None    itemid  also_view_itemid  is_train\n",
      "0       1              9433      True\n",
      "1       1              2990      True\n",
      "2       1             10750      True\n",
      "3       1             19204      True\n",
      "4       1              2991      True\n"
     ]
    }
   ],
   "source": [
    "# from meta_Grocery_and_Gourmet_Food.json\n",
    "\n",
    "# try:\n",
    "#     json\n",
    "# except NameError:\n",
    "#     json = pd.read_csv('data/json.csv.zip', low_memory=False)\n",
    "# print(json.info(), json.head())\n",
    "\n",
    "force_reload = False\n",
    "# infix = ''\n",
    "infix = '_used'\n",
    "suffix = '.zip'\n",
    "try:\n",
    "    normalized\n",
    "    if force_reload:\n",
    "        raise NameError('force_load')\n",
    "except NameError:\n",
    "    normalized = pd.read_csv(f'data/normalized{infix}.csv{suffix}', low_memory=False)\n",
    "print(normalized.info(), normalized.head())\n",
    "    \n",
    "try:\n",
    "    category\n",
    "    if force_reload:\n",
    "        raise NameError('force_load')\n",
    "except NameError:\n",
    "    category = pd.read_csv(f'data/category{infix}.csv{suffix}', low_memory=False)\n",
    "print(category.info(), category.head())\n",
    "    \n",
    "try:\n",
    "    also_view\n",
    "    if force_reload:\n",
    "        raise NameError('force_load')\n",
    "except NameError:\n",
    "    also_view = pd.read_csv(f'data/also_view{infix}.csv{suffix}', low_memory=False)\n",
    "print(also_view.info(), also_view.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">↓ ОБУЧАЮЩАЯ ВЫБОРКА ↓ (826895, 14)</th>\n",
       "      <th colspan=\"4\" halign=\"left\">↓ ТЕСТОВАЯ ВЫБОРКА ↓ (285965, 11)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>dtypes</th>\n",
       "      <th>nunique</th>\n",
       "      <th>isna</th>\n",
       "      <th>loc[0]</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>nunique</th>\n",
       "      <th>isna</th>\n",
       "      <th>loc[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>float64</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verified</th>\n",
       "      <td>bool</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>bool</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewTime</th>\n",
       "      <td>object</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10 4, 2016</td>\n",
       "      <td>object</td>\n",
       "      <td>4349.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10 1, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>object</td>\n",
       "      <td>41302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B01CPNIEQG</td>\n",
       "      <td>object</td>\n",
       "      <td>37876.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B001E5E3X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerName</th>\n",
       "      <td>object</td>\n",
       "      <td>101207.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Heather</td>\n",
       "      <td>object</td>\n",
       "      <td>86815.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Rudys Mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewText</th>\n",
       "      <td>object</td>\n",
       "      <td>686739.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>These are my FAVORITE spices in my collection....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>object</td>\n",
       "      <td>411451.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>Must Add to your Spice kitchen!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unixReviewTime</th>\n",
       "      <td>int64</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1475539200</td>\n",
       "      <td>int64</td>\n",
       "      <td>4349.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1475280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>object</td>\n",
       "      <td>311.0</td>\n",
       "      <td>712944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>object</td>\n",
       "      <td>198.0</td>\n",
       "      <td>246503.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>style</th>\n",
       "      <td>object</td>\n",
       "      <td>25892.0</td>\n",
       "      <td>398698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>object</td>\n",
       "      <td>18904.0</td>\n",
       "      <td>138285.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>object</td>\n",
       "      <td>6636.0</td>\n",
       "      <td>819916.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>object</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>283597.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <td>int64</td>\n",
       "      <td>127448.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102179</td>\n",
       "      <td>int64</td>\n",
       "      <td>109357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemid</th>\n",
       "      <td>int64</td>\n",
       "      <td>41302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37138</td>\n",
       "      <td>int64</td>\n",
       "      <td>37876.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>float64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int64</td>\n",
       "      <td>285965.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ↓ ОБУЧАЮЩАЯ ВЫБОРКА ↓ (826895, 14)                      \\\n",
       "                                           dtypes   nunique      isna   \n",
       "overall                                   float64       5.0       0.0   \n",
       "verified                                     bool       2.0       0.0   \n",
       "reviewTime                                 object    4580.0       0.0   \n",
       "asin                                       object   41302.0       0.0   \n",
       "reviewerName                               object  101207.0     164.0   \n",
       "reviewText                                 object  686739.0     274.0   \n",
       "summary                                    object  411451.0     166.0   \n",
       "unixReviewTime                              int64    4580.0       0.0   \n",
       "vote                                       object     311.0  712944.0   \n",
       "style                                      object   25892.0  398698.0   \n",
       "image                                      object    6636.0  819916.0   \n",
       "userid                                      int64  127448.0       0.0   \n",
       "itemid                                      int64   41302.0       0.0   \n",
       "rating                                    float64       2.0       0.0   \n",
       "Id                                            NaN       NaN       NaN   \n",
       "\n",
       "                                                                   \\\n",
       "                                                           loc[0]   \n",
       "overall                                                         5   \n",
       "verified                                                     True   \n",
       "reviewTime                                             10 4, 2016   \n",
       "asin                                                   B01CPNIEQG   \n",
       "reviewerName                                              Heather   \n",
       "reviewText      These are my FAVORITE spices in my collection....   \n",
       "summary                           Must Add to your Spice kitchen!   \n",
       "unixReviewTime                                         1475539200   \n",
       "vote                                                          NaN   \n",
       "style                                                         NaN   \n",
       "image                                                         NaN   \n",
       "userid                                                     102179   \n",
       "itemid                                                      37138   \n",
       "rating                                                          1   \n",
       "Id                                                            NaN   \n",
       "\n",
       "               ↓ ТЕСТОВАЯ ВЫБОРКА ↓ (285965, 11)                      \\\n",
       "                                          dtypes   nunique      isna   \n",
       "overall                                      NaN       NaN       NaN   \n",
       "verified                                    bool       2.0       0.0   \n",
       "reviewTime                                object    4349.0       0.0   \n",
       "asin                                      object   37876.0       0.0   \n",
       "reviewerName                              object   86815.0      47.0   \n",
       "reviewText                                   NaN       NaN       NaN   \n",
       "summary                                      NaN       NaN       NaN   \n",
       "unixReviewTime                             int64    4349.0       0.0   \n",
       "vote                                      object     198.0  246503.0   \n",
       "style                                     object   18904.0  138285.0   \n",
       "image                                     object    2306.0  283597.0   \n",
       "userid                                     int64  109357.0       0.0   \n",
       "itemid                                     int64   37876.0       0.0   \n",
       "rating                                       NaN       NaN       NaN   \n",
       "Id                                         int64  285965.0       0.0   \n",
       "\n",
       "                            \n",
       "                    loc[0]  \n",
       "overall                NaN  \n",
       "verified              True  \n",
       "reviewTime      10 1, 2016  \n",
       "asin            B001E5E3X0  \n",
       "reviewerName     Rudys Mom  \n",
       "reviewText             NaN  \n",
       "summary                NaN  \n",
       "unixReviewTime  1475280000  \n",
       "vote                   NaN  \n",
       "style                  NaN  \n",
       "image                  NaN  \n",
       "userid               68877  \n",
       "itemid                7506  \n",
       "rating                 NaN  \n",
       "Id                       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/1592565/determine-if-variable-is-defined-in-python/1592578#1592578\n",
    "try:\n",
    "    train\n",
    "except NameError:\n",
    "    train = pd.read_csv('data/train.csv.zip', low_memory=False)\n",
    "    train = train.drop_duplicates().reset_index(drop = True) # удалим дубликаты, если есть\n",
    "\n",
    "try:\n",
    "    test\n",
    "except NameError:\n",
    "    test = pd.read_csv('data/test.csv.zip', low_memory=False)\n",
    "\n",
    "try:\n",
    "    submission\n",
    "except NameError:\n",
    "    submission = pd.read_csv('data/sample_submission.csv.zip', low_memory=False)\n",
    "    \n",
    "# is_loaded = True\n",
    "# if not is_loaded:\n",
    "#     train = pd.read_csv('data/train.csv.zip', low_memory=False)\n",
    "#     test = pd.read_csv('data/test.csv.zip', low_memory=False)\n",
    "#     is_loaded = True\n",
    "#     submission = pd.read_csv('data/sample_submission.csv.zip', low_memory=False)\n",
    "pd.concat([param_data(train), param_data(test)], \n",
    "          axis=1, \n",
    "          keys = [f'↓ ОБУЧАЮЩАЯ ВЫБОРКА ↓ {train.shape}', f'↓ ТЕСТОВАЯ ВЫБОРКА ↓ {test.shape}'],  \n",
    "          sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание датасета:\n",
    "\n",
    "    overall - рейтинг, который поставил пользователь (значения от 1 до 5)\n",
    "    verified - был ли отзыв верифицирован (значения True или False)\n",
    "    reviewTime - когда был отзыв написан\n",
    "    asin - предположительно, серийный номер или штрихкод\n",
    "    reviewerName - имя пользователя\n",
    "    reviewText - текст отзыва\n",
    "    summary - сжатый отзыв\n",
    "    unixReviewTime - когда был отзыв написан в формате unix\n",
    "    vote - количество голосований за отзыв (значения - целые числа, представленные в виде строки)\n",
    "    style - метаданные ( значения словари с описанием размера порции и аромата продукта)\n",
    "    image - изображение продукта\n",
    "    userid - id пользователя\n",
    "    itemid - id товара\n",
    "    rating - предположительно, это понравился или не понравился товар, значения (1, если overall>=4 или 0) - target???\n",
    "    Id - id для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# itemid_asin = train[['itemid', 'asin']]\n",
    "# itemid_asin_test = test[['itemid', 'asin']]\n",
    "# print(itemid_asin.info(), itemid_asin_test.info())\n",
    "# itemid_asin = itemid_asin.drop_duplicates().reset_index(drop = True)\n",
    "# itemid_asin_test = itemid_asin_test.drop_duplicates().reset_index(drop = True)\n",
    "# print(itemid_asin.info(), itemid_asin_test.info())\n",
    "# itemid_asin_concat = pd.concat([itemid_asin, itemid_asin_test]).drop_duplicates().reset_index(drop = True)\n",
    "# print(itemid_asin_concat.info())\n",
    "# itemid_asin_concat.to_csv('data/itemid_asin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41302 entries, 0 to 41301\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   itemid  41302 non-null  int64 \n",
      " 1   asin    41302 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 645.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "itemid_asin = train[['itemid', 'asin']]\n",
    "# itemid_asin_test = test[['itemid', 'asin']]\n",
    "# print(itemid_asin.info(), itemid_asin_test.info())\n",
    "itemid_asin = itemid_asin.drop_duplicates().reset_index(drop = True)\n",
    "# itemid_asin_test = itemid_asin_test.drop_duplicates().reset_index(drop = True)\n",
    "# print(itemid_asin.info(), itemid_asin_test.info())\n",
    "# itemid_asin_concat = pd.concat([itemid_asin, itemid_asin_test]).drop_duplicates().reset_index(drop = True)\n",
    "print(itemid_asin.info())\n",
    "itemid_asin.to_csv('data/itemid_asin_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ полей исходного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отберем поля "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для обучающего датасета, поочередно рассматривая колонки исходного датасета:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overall - рейтинг, который поставил пользователь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"overall\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 5\n",
      "------\n",
      "5.0    592278\n",
      "4.0    109334\n",
      "3.0     58488\n",
      "1.0     36159\n",
      "2.0     30636\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'overall'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"rating_check\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 2\n",
      "------\n",
      "1.0    701612\n",
      "0.0    125283\n",
      "Name: rating_check, dtype: int64\n",
      "Колонка \"rating\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 2\n",
      "------\n",
      "1.0    701612\n",
      "0.0    125283\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['rating_check'] = train['overall'].apply(lambda x: 1.0 if x >= 4 else 0.0)\n",
    "describe(df, 'rating_check')\n",
    "describe(df, 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение этого поля отражено в колонке `rating`, не включаем его в список далее рассматриваемых"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"verified\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 2\n",
      "------\n",
      "True     718164\n",
      "False    108731\n",
      "Name: verified, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'verified'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Надо бы drop'нуть все неверифицированные отзывы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"asin\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 41302\n",
      "------\n",
      "B00BUKL666    5430\n",
      "B00D3M2QP4    4733\n",
      "B008QMX2SG    4611\n",
      "B00R7PWK7W    2449\n",
      "B000F4DKAI    2166\n",
      "              ... \n",
      "B0013JLTIY       1\n",
      "B00112I1PW       1\n",
      "B008J46E9A       1\n",
      "B000FDLB9Q       1\n",
      "B00BB1DPOA       1\n",
      "Name: asin, Length: 41302, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'asin'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"itemid\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 41302\n",
      "------\n",
      "22208    5430\n",
      "23540    4733\n",
      "24556    4611\n",
      "32046    2449\n",
      "1919     2166\n",
      "         ... \n",
      "38777       1\n",
      "32616       1\n",
      "5396        1\n",
      "25613       1\n",
      "38602       1\n",
      "Name: itemid, Length: 41302, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "describe(df, 'itemid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что рассматриваемая колонка и `itemid`, это про одно и тоже - код товара, поэтому рассматриваемую колонку игонорируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewerName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"reviewerName\":\n",
      "------\n",
      "na: 164\n",
      "уникальных значений: 101208\n",
      "------\n",
      "Amazon Customer      30612\n",
      "Kindle Customer       6012\n",
      "Linda                  713\n",
      "John                   695\n",
      "David                  597\n",
      "                     ...  \n",
      "beautybydesign           1\n",
      "J mom with kids          1\n",
      "Peter M. Rossetti        1\n",
      "XH                       1\n",
      "Ted Bear                 1\n",
      "Name: reviewerName, Length: 101207, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'reviewerName'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"userid\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 127448\n",
      "------\n",
      "842       418\n",
      "17987     311\n",
      "355       294\n",
      "2024      288\n",
      "2809      263\n",
      "         ... \n",
      "30644       1\n",
      "64828       1\n",
      "104926      1\n",
      "63804       1\n",
      "38947       1\n",
      "Name: userid, Length: 127448, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "describe(df, 'userid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поле `userid` выглядит точнее, чем рассматриваемая колонка, поэтому ее тоже игнорируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"reviewText\":\n",
      "------\n",
      "na: 274\n",
      "уникальных значений: 686740\n",
      "------\n",
      "good                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          3019\n",
      "great                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2525\n",
      "Great                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2002\n",
      "Good                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1977\n",
      "ok                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1278\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ... \n",
      "I was so excited to discover Gingerbread Twix, as soon as the package arrived, I tore open the bag and bit into one.  I did enjoy these, but I was suprised by the flavor, I expected the \"cookie\" part to have the gingerbread flavors, not the caramel. These were great as holiday stocking stuffers.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
      "DID NOT KNOW THAT YOU COULD MAKE PORK JERKY. THE BEST! GOOD SLICES, MOIST, TENDER. I WILL BUY AGAIN SOON.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
      "This is great tasting coffee!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
      "Republic of Tea, even though somewhat pricier than other brands, has been one of my top choices for tea for a long time and Earl Grey tea has been my all time favorite ever since I first tasted it. I LOVE the slightly tart zing of Bergamot, and this 'Earl Greyer' delivers every single time.\\n\\nJust as a point of interest to any tea lover: I drink A LOT OF TEA and over the years I have tasted endless variety of brands and flavors...  finally narrowed my choices down to these few:\\nafter #1, Earl Grey the King, there are only additional three that I would give enthusiastic thumbs up:\\nBlackberry Sage,\\nMango Ceylon (both Republic of Tea brands)\\nand then then there is one accidental and delightful find - Focus Tea by Tazo brand (BTW Tazo makes quite tasty and flavorful Earl Grey as well).\\nFocus is fairly new and relatively unknown delectable proprietary blend of black tea, roasted yerba mate, orange essence and cocoa peel and I was most pleasantly surprised to find out how uniquely delicious (and how very comparable with Earl Grey) the taste was.\\n\\nThere are few people (men mostly, from my experience), that just do not like flavored stuff, and prefer their tea and/or coffee neutral, with no 'extra' taste.  If you are one of those, then none of my choices would meet your standards, as they all have pretty distinct (although all natural, non-artificial) flavor.\\n\\nIf nice, balanced fruity (and stressing once again, NATURAL) flavor is, what you prefer in your tea, then definitely give this brand a try, you will not regret!!       1\n",
      "I really enjoy the taste of Fogchaser single serving cups. I try new kinds of k-cups, and they're never as good. Fogchaser is the best.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      "Name: reviewText, Length: 686739, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'reviewText'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"summary\":\n",
      "------\n",
      "na: 166\n",
      "уникальных значений: 411452\n",
      "------\n",
      "Five Stars                                        167416\n",
      "Four Stars                                         26010\n",
      "Three Stars                                        11682\n",
      "One Star                                            5206\n",
      "Two Stars                                           4824\n",
      "                                                   ...  \n",
      "Great crunchy cracker                                  1\n",
      "Sushi Nori                                             1\n",
      "Bummer.  Perfumey after taste                          1\n",
      "THANK GOD these come in single serving pouches         1\n",
      "Great price, great size                                1\n",
      "Name: summary, Length: 411451, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'summary'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unixReviewTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"unixReviewTime\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 4580\n",
      "------\n",
      "1456790400    909\n",
      "1468454400    858\n",
      "1433289600    769\n",
      "1453248000    764\n",
      "1455926400    753\n",
      "             ... \n",
      "1105142400      1\n",
      "1131062400      1\n",
      "1161993600      1\n",
      "1142467200      1\n",
      "1177113600      1\n",
      "Name: unixReviewTime, Length: 4580, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'unixReviewTime'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"reviewTime\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 4580\n",
      "------\n",
      "03 1, 2016     909\n",
      "07 14, 2016    858\n",
      "06 3, 2015     769\n",
      "01 20, 2016    764\n",
      "02 20, 2016    753\n",
      "              ... \n",
      "06 4, 2006       1\n",
      "04 27, 2007      1\n",
      "09 5, 2005       1\n",
      "08 11, 2006      1\n",
      "11 25, 2006      1\n",
      "Name: reviewTime, Length: 4580, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'reviewTime'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта колонка про то же самое, что и `unixReviewTime`, только в другом формате. Игнорируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"vote\":\n",
      "------\n",
      "na: 712944\n",
      "уникальных значений: 312\n",
      "------\n",
      "2        42820\n",
      "3        21447\n",
      "4        12337\n",
      "5         7932\n",
      "6         5480\n",
      "         ...  \n",
      "349          1\n",
      "414          1\n",
      "1,491        1\n",
      "208          1\n",
      "221          1\n",
      "Name: vote, Length: 311, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'vote'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"style\":\n",
      "------\n",
      "na: 398698\n",
      "уникальных значений: 25893\n",
      "------\n",
      "{'Size:': ' Pack of 1'}                                                                      4549\n",
      "{'Package Quantity:': ' 1'}                                                                  4461\n",
      "{'Package Type:': ' Standard Packaging'}                                                     3860\n",
      "{'Size:': ' 1 Pack'}                                                                         3688\n",
      "{'Size:': ' 24 Count'}                                                                       3615\n",
      "                                                                                             ... \n",
      "{'Size:': ' 6 Pack', 'Flavor:': ' Wholesome Bread'}                                             1\n",
      "{'Size:': ' 12 count', 'Flavor:': ' Donut Blend Coffee'}                                        1\n",
      "{'Size:': ' Traditional Chocolate'}                                                             1\n",
      "{'Size:': ' 5 Ounce (Pack of 4)', 'Flavor:': ' Brownie'}                                        1\n",
      "{'Size:': ' 0.87-Ounce (Pack of 12)', 'Flavor:': ' Italian Herb Baked Chicken and Pasta'}       1\n",
      "Name: style, Length: 25892, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'style'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту колонку оставляем для дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"image\":\n",
      "------\n",
      "na: 819916\n",
      "уникальных значений: 6637\n",
      "------\n",
      "['https://images-na.ssl-images-amazon.com/images/I/712zJIOTV5L._SY88.jpg']                                                                                                                                                                                                                                                                                                                                                                                      6\n",
      "['https://images-na.ssl-images-amazon.com/images/I/71+Z1TA3eyL._SY88.jpg']                                                                                                                                                                                                                                                                                                                                                                                      6\n",
      "['https://images-na.ssl-images-amazon.com/images/I/81h8Zc+1rzL._SY88.jpg']                                                                                                                                                                                                                                                                                                                                                                                      5\n",
      "['https://images-na.ssl-images-amazon.com/images/I/81kah7EsJtL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/81YnU7oiOIL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/81j+y7+3NxL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/81RV96qYZvL._SY88.jpg']                                                                                                                                                        5\n",
      "['https://images-na.ssl-images-amazon.com/images/I/41wx9Sn88cL._SY88.jpg']                                                                                                                                                                                                                                                                                                                                                                                      5\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                               ..\n",
      "['https://images-na.ssl-images-amazon.com/images/I/71C+Ow9-xkL._SY88.jpg']                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      "['https://images-na.ssl-images-amazon.com/images/I/71kbsqvf0pL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71OC9KK6nIL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71WNexPAS8L._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71PpelJEidL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/714Z5u5no6L._SY88.jpg']                                                                              1\n",
      "['https://images-na.ssl-images-amazon.com/images/I/61isLl8xlkL._SY88.jpg']                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      "['https://images-na.ssl-images-amazon.com/images/I/717WRd133wL._SY88.jpg']                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      "['https://images-na.ssl-images-amazon.com/images/I/61GFej8KmPL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/81TUuumoptL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/8150kFkpBXL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/817RTEWwQFL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/61SZS2WtWGL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71pUs20T3vL._SY88.jpg']    1\n",
      "Name: image, Length: 6636, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "field_name = 'image'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: здесь в лучшем случае мы можем использовать количество картинок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### userid, itemid, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 127495, unique: 127448\n"
     ]
    }
   ],
   "source": [
    "print(f\"max: {df.userid.max()}, unique: {len(df.userid.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reviews_per_book = df.groupby( 'userid' ).userid.apply( lambda x: len( x ))\n",
    "# userid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 41319, unique: 41302\n"
     ]
    }
   ],
   "source": [
    "print(f\"max: {df.itemid.max()}, unique: {len(df.itemid.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти поля безусловно рассматриваем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field_name in ['userid', 'itemid', 'rating']:\n",
    "    selected_fields.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем данные для построения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 718164 entries, 0 to 826894\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         718164 non-null  float64\n",
      " 1   verified        718164 non-null  bool   \n",
      " 2   reviewTime      718164 non-null  object \n",
      " 3   asin            718164 non-null  object \n",
      " 4   reviewerName    718024 non-null  object \n",
      " 5   reviewText      717907 non-null  object \n",
      " 6   summary         718008 non-null  object \n",
      " 7   unixReviewTime  718164 non-null  int64  \n",
      " 8   vote            93604 non-null   object \n",
      " 9   style           370202 non-null  object \n",
      " 10  image           4527 non-null    object \n",
      " 11  userid          718164 non-null  int64  \n",
      " 12  itemid          718164 non-null  int64  \n",
      " 13  rating          718164 non-null  float64\n",
      " 14  rating_check    718164 non-null  float64\n",
      "dtypes: bool(1), float64(3), int64(3), object(8)\n",
      "memory usage: 82.9+ MB\n"
     ]
    }
   ],
   "source": [
    "sdf = df[df.verified == True] # [list(selected_fields)]\n",
    "sdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 826895 entries, 0 to 826894\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         826895 non-null  float64\n",
      " 1   verified        826895 non-null  bool   \n",
      " 2   reviewTime      826895 non-null  object \n",
      " 3   asin            826895 non-null  object \n",
      " 4   reviewerName    826731 non-null  object \n",
      " 5   reviewText      826621 non-null  object \n",
      " 6   summary         826729 non-null  object \n",
      " 7   unixReviewTime  826895 non-null  int64  \n",
      " 8   vote            113951 non-null  object \n",
      " 9   style           428197 non-null  object \n",
      " 10  image           6979 non-null    object \n",
      " 11  userid          826895 non-null  int64  \n",
      " 12  itemid          826895 non-null  int64  \n",
      " 13  rating          826895 non-null  float64\n",
      "dtypes: bool(1), float64(2), int64(3), object(8)\n",
      "memory usage: 82.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 718164 entries, 0 to 826894\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         718164 non-null  float64\n",
      " 1   verified        718164 non-null  bool   \n",
      " 2   reviewTime      718164 non-null  object \n",
      " 3   asin            718164 non-null  object \n",
      " 4   reviewerName    718024 non-null  object \n",
      " 5   reviewText      717907 non-null  object \n",
      " 6   summary         718008 non-null  object \n",
      " 7   unixReviewTime  718164 non-null  int64  \n",
      " 8   vote            93604 non-null   object \n",
      " 9   style           370202 non-null  object \n",
      " 10  image           4527 non-null    object \n",
      " 11  userid          718164 non-null  int64  \n",
      " 12  itemid          718164 non-null  int64  \n",
      " 13  rating          718164 non-null  float64\n",
      " 14  rating_check    718164 non-null  float64\n",
      "dtypes: bool(1), float64(3), int64(3), object(8)\n",
      "memory usage: 82.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())\n",
    "print(sdf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(train,random_state=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка \"rating\":\n",
      "------\n",
      "na: 0\n",
      "уникальных значений: 2\n",
      "------\n",
      "1.0    526498\n",
      "0.0     93673\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "describe(train_data, 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_coo = sparse.coo_matrix((train_data['rating'].astype(int),\n",
    "                                 (train_data['userid'],\n",
    "                                  train_data['itemid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206724\n",
      "206724\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data.userid.values))\n",
    "print(len(test_data.itemid.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.sparse as sparse\n",
    "le = LabelEncoder()\n",
    "le.fit(category.category)\n",
    "category['category_code']=le.transform(category.category)\n",
    "item_features  = sparse.coo_matrix(([1]*len(category),(category.itemid,category.category_code)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим модель и считаем roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for no_components=30, learning_rate=0.1, epochs=30 . . .\n"
     ]
    }
   ],
   "source": [
    "NUM_THREADS = 4 #число потоков\n",
    "\n",
    "model_prev = None\n",
    "no_components_prev = None\n",
    "learning_rate_prev = None\n",
    "\n",
    "def get_model(no_components, learning_rate):\n",
    "    global model_prev, no_components_prev, learning_rate_prev\n",
    "    model = model_prev if model_prev is not None and no_components_prev == no_components else LightFM(loss='logistic',learning_rate=learning_rate, no_components=no_components)\n",
    "    model_prev = model  \n",
    "    learning_rate_prev = learning_rate\n",
    "    no_components_prev = no_components\n",
    "    return model\n",
    "\n",
    "def fit_model(no_components, learning_rate, epochs):\n",
    "    model = get_model(no_components, learning_rate)\n",
    "    model = model.fit(ratings_coo, epochs=epochs, num_threads=NUM_THREADS)\n",
    "# model = model.fit(ratings_coo, epochs=epochs, num_threads=NUM_THREADS,item_features=item_features)\n",
    "    return model\n",
    "\n",
    "def get_roc_auc_score(params):   \n",
    "    no_components = params[\"no_components\"][\"actual\"]\n",
    "    learning_rate = params[\"learning_rate\"][\"actual\"]\n",
    "    learning_rate_round = params[\"learning_rate\"][\"round\"]\n",
    "    epochs = params[\"epochs\"][\"actual\"]\n",
    "    print(f\"model for no_components={no_components}, learning_rate={round(learning_rate, learning_rate_round)}, epochs={epochs} . . .\")\n",
    "    import time\n",
    "    start = time.time()\n",
    "    model = fit_model(no_components, learning_rate, epochs)\n",
    "    print(len(test_data.userid.values), len(test_data.itemid.values))\n",
    "    preds = model.predict(test_data.userid.values, test_data.itemid.values)\n",
    "    roc_auc_score = sklearn.metrics.roc_auc_score(test_data.rating, preds)\n",
    "    print(f\"{round(time.time() - start, 1)}s, roc_auc_score: {round(roc_auc_score, 5)}\")\n",
    "    return roc_auc_score\n",
    "    \n",
    "no_components = 30\n",
    "learning_rate = 0.1\n",
    "epochs = 30\n",
    "params = {\n",
    "    \"no_components\": {\n",
    "        \"actual\": 30,\n",
    "    },\n",
    "    \"learning_rate\": {\n",
    "        \"actual\": 0.1,\n",
    "        \"round\": 3,\n",
    "    },\n",
    "    \"epochs\": {\n",
    "        \"actual\": 30,\n",
    "    },\n",
    "}\n",
    "roc_auc_score = get_roc_auc_score(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Подберем гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual():\n",
    "    global no_components_min, no_components, epochs_min, epochs, learning_rate_min, learning_rate\n",
    "    no_components_actual = no_components_min if no_components < no_components_min else no_components\n",
    "    epochs_actual = epochs_min if epochs < epochs_min else epochs\n",
    "    learning_rate_actual = learning_rate_min if learning_rate < learning_rate_min else learning_rate\n",
    "    return no_components_actual, learning_rate_actual, epochs_actual\n",
    "    \n",
    "params = {\n",
    "    \"epochs\": {\n",
    "        \"val\": 0,\n",
    "        \"min\": 1,\n",
    "        \"step\": 8,\n",
    "        \"step_min_abs\": 1,\n",
    "        \"round\": 0,  \n",
    "    },\n",
    "    \"no_components\": {\n",
    "        \"val\": 0,\n",
    "        \"min\": 1,\n",
    "        \"step\": 128,\n",
    "        \"step_min_abs\": 1,\n",
    "        \"round\": 0,  \n",
    "    },\n",
    "    \"learning_rate\": {\n",
    "        \"val\": 0.1,\n",
    "        \"min\": 0.005,\n",
    "        \"step\": 0.1,\n",
    "        \"step_min_abs\": 0.005,\n",
    "        \"round\": 3,\n",
    "    },\n",
    "}\n",
    "        \n",
    "def update_actual():\n",
    "    global params\n",
    "    for k, v in params.items():\n",
    "        v[\"actual\"] = v[\"min\"] if v[\"val\"] < v[\"min\"] else v[\"val\"]\n",
    "        \n",
    "def stat():\n",
    "    global params\n",
    "    s = ''\n",
    "    update_actual()\n",
    "    for k, v in params.items():\n",
    "        if len(s) > 0:\n",
    "            s = s + \", \"\n",
    "        s = s + f'{k}: {v[\"actual\"]}/{v[\"step\"]}'\n",
    "    return s\n",
    "\n",
    "\n",
    "delta_min = 0.00001\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "print(\"Start . . .\")\n",
    "roc_auc = 0\n",
    "import math\n",
    "while True: \n",
    "    for k, v in params.items():\n",
    "        v[\"roc_auc_delta\"] = 0 \n",
    "\n",
    "    delta = 0\n",
    "    delta_neg = 0\n",
    "    for k, v in params.items():\n",
    "        if abs(v[\"step\"]) >= v[\"step_min_abs\"]:\n",
    "            update_actual()\n",
    "            v[\"actual\"] = v[\"val\"] + v[\"step\"]\n",
    "            v[\"roc_auc_delta\"] = get_roc_auc_score(params) - roc_auc\n",
    "            if v[\"roc_auc_delta\"] > delta:\n",
    "                delta = v[\"roc_auc_delta\"]\n",
    "            elif v[\"roc_auc_delta\"] < delta_neg:\n",
    "                delta_neg = v[\"roc_auc_delta\"]\n",
    "\n",
    "    if delta >= delta_min:\n",
    "        for k, v in params.items():\n",
    "            if v[\"roc_auc_delta\"] >= delta:\n",
    "                v[\"val\"] = v[\"val\"] + v[\"step\"]\n",
    "        roc_auc = roc_auc + delta\n",
    "        \n",
    "        print(f\"roc_auc: {round(roc_auc, 5)}, delta: {round(delta, 5)} for {stat()}\")   \n",
    "    else:\n",
    "        need_stop_by_min_abs = True\n",
    "        for k, v in params.items():\n",
    "            if abs(v[\"step\"]) > v[\"step_min_abs\"]:\n",
    "                need_stop_by_min_abs = False\n",
    "                break\n",
    "        if need_stop_by_min_abs:\n",
    "            print(\"Stopped by step_min_abs\")\n",
    "            break \n",
    "        elif -delta_neg < delta_min:\n",
    "            print(f\"Stopped by delta_min: -delta_neg={-delta_neg}\")\n",
    "            break\n",
    "        else:\n",
    "            did_change_step = False\n",
    "            for k, v in params.items():\n",
    "                if abs(v[\"step\"]) > v[\"step_min_abs\"] and v[\"roc_auc_delta\"] <= delta_neg:\n",
    "                    v[\"step\"] = -round(math.copysign(abs(v[\"step\"])/2, v[\"step\"]), v[\"round\"])\n",
    "                    if v[\"round\"] == 0:\n",
    "                        v[\"step\"] = int(v[\"step\"])              \n",
    "                    print(f'{k}_step: {v[\"step\"]}')\n",
    "                    did_change_step = True\n",
    "                    break\n",
    "            if not did_change_step:\n",
    "                print(\"Stopped by step_min_abs\")\n",
    "                break\n",
    "            \n",
    "print(f\"{round(time.time() - start, 1)}s, Ready: roc_auc={round(roc_auc, 5)} for {stat()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим модель с подобранными гиперпараметрами, считаем roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_actual()\n",
    "no_components = params[\"no_components\"][\"actual\"]\n",
    "learning_rate = params[\"learning_rate\"][\"actual\"]\n",
    "epochs = params[\"epochs\"][\"actual\"]\n",
    "\n",
    "# для всего train'а:\n",
    "# no_components = 128\n",
    "# epochs = 7\n",
    "# learning_rate = 0.225\n",
    "\n",
    "# для verified его части:\n",
    "# no_components = 128\n",
    "# epochs = 10\n",
    "# learning_rate = 0.187\n",
    "\n",
    "# для verified его части (другой вариант):\n",
    "# no_components = 128\n",
    "# epochs = 6\n",
    "# learning_rate = 0.275\n",
    "\n",
    "model = fit_model(no_components, learning_rate, epochs)\n",
    "preds = model.predict(test_data.userid.values, test_data.itemid.values)\n",
    "roc_auc_score = sklearn.metrics.roc_auc_score(test_data.rating,preds)\n",
    "print(f'roc_auc_score: {round(roc_auc_score, 5)} for {stat()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test.userid.values, test.itemid.values)\n",
    "preds.min(), preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_preds = (preds - preds.min())/(preds - preds.min()).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_preds.min(), normalized_preds.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-43e298e4c521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalized_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'normalized_preds' is not defined"
     ]
    }
   ],
   "source": [
    "normalized_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['rating'] = normalized_preds\n",
    "submission.to_csv('submission_fm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l2: 0.12065\tvalid_0's l1: 0.242037\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l2: 0.120604\tvalid_0's l1: 0.242046\n",
      "[3]\tvalid_0's l2: 0.120558\tvalid_0's l1: 0.242022\n",
      "[4]\tvalid_0's l2: 0.120541\tvalid_0's l1: 0.242005\n",
      "[5]\tvalid_0's l2: 0.120516\tvalid_0's l1: 0.241981\n",
      "[6]\tvalid_0's l2: 0.120501\tvalid_0's l1: 0.241695\n",
      "[7]\tvalid_0's l2: 0.120498\tvalid_0's l1: 0.241522\n",
      "[8]\tvalid_0's l2: 0.120482\tvalid_0's l1: 0.2414\n",
      "[9]\tvalid_0's l2: 0.120465\tvalid_0's l1: 0.241321\n",
      "[10]\tvalid_0's l2: 0.120451\tvalid_0's l1: 0.241266\n",
      "[11]\tvalid_0's l2: 0.120447\tvalid_0's l1: 0.241195\n",
      "[12]\tvalid_0's l2: 0.120444\tvalid_0's l1: 0.241146\n",
      "[13]\tvalid_0's l2: 0.120442\tvalid_0's l1: 0.241115\n",
      "[14]\tvalid_0's l2: 0.120445\tvalid_0's l1: 0.241103\n",
      "[15]\tvalid_0's l2: 0.12042\tvalid_0's l1: 0.241068\n",
      "[16]\tvalid_0's l2: 0.120415\tvalid_0's l1: 0.241167\n",
      "[17]\tvalid_0's l2: 0.120401\tvalid_0's l1: 0.241202\n",
      "[18]\tvalid_0's l2: 0.120402\tvalid_0's l1: 0.241234\n",
      "[19]\tvalid_0's l2: 0.120397\tvalid_0's l1: 0.24124\n",
      "[20]\tvalid_0's l2: 0.120388\tvalid_0's l1: 0.241233\n",
      "[21]\tvalid_0's l2: 0.120385\tvalid_0's l1: 0.241171\n",
      "[22]\tvalid_0's l2: 0.120375\tvalid_0's l1: 0.241122\n",
      "[23]\tvalid_0's l2: 0.120368\tvalid_0's l1: 0.241094\n",
      "[24]\tvalid_0's l2: 0.120362\tvalid_0's l1: 0.241065\n",
      "[25]\tvalid_0's l2: 0.12035\tvalid_0's l1: 0.241035\n",
      "[26]\tvalid_0's l2: 0.120346\tvalid_0's l1: 0.241157\n",
      "[27]\tvalid_0's l2: 0.120337\tvalid_0's l1: 0.241222\n",
      "[28]\tvalid_0's l2: 0.120333\tvalid_0's l1: 0.241264\n",
      "[29]\tvalid_0's l2: 0.120332\tvalid_0's l1: 0.241289\n",
      "[30]\tvalid_0's l2: 0.120333\tvalid_0's l1: 0.241298\n",
      "[31]\tvalid_0's l2: 0.120329\tvalid_0's l1: 0.241307\n",
      "[32]\tvalid_0's l2: 0.120322\tvalid_0's l1: 0.2413\n",
      "[33]\tvalid_0's l2: 0.120321\tvalid_0's l1: 0.241307\n",
      "[34]\tvalid_0's l2: 0.120324\tvalid_0's l1: 0.241306\n",
      "[35]\tvalid_0's l2: 0.12032\tvalid_0's l1: 0.241298\n",
      "[36]\tvalid_0's l2: 0.120317\tvalid_0's l1: 0.241265\n",
      "[37]\tvalid_0's l2: 0.120309\tvalid_0's l1: 0.241247\n",
      "[38]\tvalid_0's l2: 0.120308\tvalid_0's l1: 0.241229\n",
      "[39]\tvalid_0's l2: 0.120302\tvalid_0's l1: 0.241213\n",
      "[40]\tvalid_0's l2: 0.120293\tvalid_0's l1: 0.241203\n",
      "[41]\tvalid_0's l2: 0.120295\tvalid_0's l1: 0.241265\n",
      "[42]\tvalid_0's l2: 0.120293\tvalid_0's l1: 0.241298\n",
      "[43]\tvalid_0's l2: 0.12029\tvalid_0's l1: 0.24131\n",
      "[44]\tvalid_0's l2: 0.120285\tvalid_0's l1: 0.24132\n",
      "[45]\tvalid_0's l2: 0.120287\tvalid_0's l1: 0.241325\n",
      "[46]\tvalid_0's l2: 0.120284\tvalid_0's l1: 0.241275\n",
      "[47]\tvalid_0's l2: 0.120285\tvalid_0's l1: 0.241244\n",
      "[48]\tvalid_0's l2: 0.120279\tvalid_0's l1: 0.241217\n",
      "[49]\tvalid_0's l2: 0.120274\tvalid_0's l1: 0.241201\n",
      "[50]\tvalid_0's l2: 0.120275\tvalid_0's l1: 0.24119\n",
      "[51]\tvalid_0's l2: 0.120274\tvalid_0's l1: 0.241256\n",
      "[52]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.241298\n",
      "[53]\tvalid_0's l2: 0.12027\tvalid_0's l1: 0.241321\n",
      "[54]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.241331\n",
      "[55]\tvalid_0's l2: 0.120274\tvalid_0's l1: 0.241339\n",
      "[56]\tvalid_0's l2: 0.120275\tvalid_0's l1: 0.24117\n",
      "[57]\tvalid_0's l2: 0.120274\tvalid_0's l1: 0.241065\n",
      "[58]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240993\n",
      "[59]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240954\n",
      "[60]\tvalid_0's l2: 0.120264\tvalid_0's l1: 0.24093\n",
      "[61]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240957\n",
      "[62]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.240971\n",
      "[63]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.24098\n",
      "[64]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240987\n",
      "[65]\tvalid_0's l2: 0.120265\tvalid_0's l1: 0.24099\n",
      "[66]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.240899\n",
      "[67]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240852\n",
      "[68]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240812\n",
      "[69]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.240791\n",
      "[70]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.240778\n",
      "[71]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240783\n",
      "[72]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240785\n",
      "[73]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.24078\n",
      "[74]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.240773\n",
      "[75]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.240772\n",
      "[76]\tvalid_0's l2: 0.120249\tvalid_0's l1: 0.240937\n",
      "[77]\tvalid_0's l2: 0.120247\tvalid_0's l1: 0.241041\n",
      "[78]\tvalid_0's l2: 0.120248\tvalid_0's l1: 0.241106\n",
      "[79]\tvalid_0's l2: 0.120251\tvalid_0's l1: 0.241141\n",
      "[80]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.241164\n",
      "[81]\tvalid_0's l2: 0.12025\tvalid_0's l1: 0.241103\n",
      "[82]\tvalid_0's l2: 0.120246\tvalid_0's l1: 0.241067\n",
      "[83]\tvalid_0's l2: 0.120246\tvalid_0's l1: 0.241039\n",
      "[84]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.241039\n",
      "[85]\tvalid_0's l2: 0.120254\tvalid_0's l1: 0.241022\n",
      "[86]\tvalid_0's l2: 0.120254\tvalid_0's l1: 0.241007\n",
      "[87]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.240994\n",
      "[88]\tvalid_0's l2: 0.120255\tvalid_0's l1: 0.240984\n",
      "[89]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.240974\n",
      "[90]\tvalid_0's l2: 0.120252\tvalid_0's l1: 0.240974\n",
      "[91]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.240906\n",
      "[92]\tvalid_0's l2: 0.120255\tvalid_0's l1: 0.240865\n",
      "[93]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240842\n",
      "[94]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240824\n",
      "[95]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240815\n",
      "[96]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.24095\n",
      "[97]\tvalid_0's l2: 0.120253\tvalid_0's l1: 0.241034\n",
      "[98]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.241086\n",
      "[99]\tvalid_0's l2: 0.120255\tvalid_0's l1: 0.241113\n",
      "[100]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.241125\n",
      "[101]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.241017\n",
      "[102]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240946\n",
      "[103]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.2409\n",
      "[104]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240876\n",
      "[105]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.240855\n",
      "[106]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240906\n",
      "[107]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240941\n",
      "[108]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240958\n",
      "[109]\tvalid_0's l2: 0.120264\tvalid_0's l1: 0.240971\n",
      "[110]\tvalid_0's l2: 0.120265\tvalid_0's l1: 0.240974\n",
      "[111]\tvalid_0's l2: 0.120264\tvalid_0's l1: 0.240832\n",
      "[112]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240748\n",
      "[113]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240694\n",
      "[114]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240668\n",
      "[115]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240639\n",
      "[116]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240683\n",
      "[117]\tvalid_0's l2: 0.120265\tvalid_0's l1: 0.240713\n",
      "[118]\tvalid_0's l2: 0.120264\tvalid_0's l1: 0.240729\n",
      "[119]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240738\n",
      "[120]\tvalid_0's l2: 0.120259\tvalid_0's l1: 0.240744\n",
      "[121]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240854\n",
      "[122]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240916\n",
      "[123]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240955\n",
      "[124]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240983\n",
      "[125]\tvalid_0's l2: 0.12026\tvalid_0's l1: 0.240995\n",
      "[126]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240921\n",
      "[127]\tvalid_0's l2: 0.120254\tvalid_0's l1: 0.240873\n",
      "[128]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240851\n",
      "[129]\tvalid_0's l2: 0.120259\tvalid_0's l1: 0.240837\n",
      "[130]\tvalid_0's l2: 0.120258\tvalid_0's l1: 0.240832\n",
      "[131]\tvalid_0's l2: 0.120257\tvalid_0's l1: 0.240844\n",
      "[132]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.24085\n",
      "[133]\tvalid_0's l2: 0.12026\tvalid_0's l1: 0.240851\n",
      "[134]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240854\n",
      "[135]\tvalid_0's l2: 0.120265\tvalid_0's l1: 0.240862\n",
      "[136]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240808\n",
      "[137]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240774\n",
      "[138]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240754\n",
      "[139]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240742\n",
      "[140]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240733\n",
      "[141]\tvalid_0's l2: 0.120256\tvalid_0's l1: 0.240723\n",
      "[142]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240723\n",
      "[143]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240722\n",
      "[144]\tvalid_0's l2: 0.120267\tvalid_0's l1: 0.240722\n",
      "[145]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240716\n",
      "[146]\tvalid_0's l2: 0.120267\tvalid_0's l1: 0.240843\n",
      "[147]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240915\n",
      "[148]\tvalid_0's l2: 0.12027\tvalid_0's l1: 0.240959\n",
      "[149]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240983\n",
      "[150]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.240998\n",
      "[151]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240975\n",
      "[152]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240961\n",
      "[153]\tvalid_0's l2: 0.120266\tvalid_0's l1: 0.240958\n",
      "[154]\tvalid_0's l2: 0.120267\tvalid_0's l1: 0.240957\n",
      "[155]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240948\n",
      "[156]\tvalid_0's l2: 0.12026\tvalid_0's l1: 0.240908\n",
      "[157]\tvalid_0's l2: 0.120259\tvalid_0's l1: 0.240885\n",
      "[158]\tvalid_0's l2: 0.120261\tvalid_0's l1: 0.240875\n",
      "[159]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240865\n",
      "[160]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240859\n",
      "[161]\tvalid_0's l2: 0.120262\tvalid_0's l1: 0.240779\n",
      "[162]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\tvalid_0's l2: 0.120263\tvalid_0's l1: 0.240702\n",
      "[164]\tvalid_0's l2: 0.120267\tvalid_0's l1: 0.240686\n",
      "[165]\tvalid_0's l2: 0.12027\tvalid_0's l1: 0.240683\n",
      "[166]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240765\n",
      "[167]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.240816\n",
      "[168]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240837\n",
      "[169]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240854\n",
      "[170]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.24086\n",
      "[171]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240879\n",
      "[172]\tvalid_0's l2: 0.120268\tvalid_0's l1: 0.240892\n",
      "[173]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.240898\n",
      "[174]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240898\n",
      "[175]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240895\n",
      "[176]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240892\n",
      "[177]\tvalid_0's l2: 0.120269\tvalid_0's l1: 0.240897\n",
      "[178]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240901\n",
      "[179]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.240898\n",
      "[180]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.2409\n",
      "[181]\tvalid_0's l2: 0.120272\tvalid_0's l1: 0.240751\n",
      "[182]\tvalid_0's l2: 0.120271\tvalid_0's l1: 0.24066\n",
      "[183]\tvalid_0's l2: 0.12027\tvalid_0's l1: 0.240606\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's l2: 0.120246\tvalid_0's l1: 0.241039\n",
      "Starting predicting...\n",
      "The roc_auc_score of prediction is: 0.5526532642022016\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_data_GB = pd.DataFrame({\n",
    "    'userid': sdf['userid'],\n",
    "    'itemid': sdf['itemid'],\n",
    "    'rating': sdf['rating']\n",
    "})\n",
    "\n",
    "test_data_GB = pd.DataFrame({\n",
    "    'userid': test['userid'],\n",
    "    'itemid': test['itemid'],\n",
    "})\n",
    "train_data_GB_train, test_data_GB_test = train_test_split(train_data_GB,random_state=13, shuffle=True)\n",
    "y_train = train_data_GB_train['rating']\n",
    "y_test = test_data_GB_test['rating']\n",
    "X_train = train_data_GB_train.drop('rating', axis=1)\n",
    "X_test = test_data_GB_test.drop('rating', axis=1)\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 8,\n",
    "    'learning_rate': 0.4,\n",
    "    'feature_fraction': 0.1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=200,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=100)\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The roc_auc_score of prediction is:', sklearn.metrics.roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# y____ =  gbm.predict(test_data_GB, num_iteration=gbm.best_iteration)\n",
    "# c = (normalized_preds  + y____) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_gbm = gbm.predict(test_data_GB, num_iteration=gbm.best_iteration)\n",
    "preds_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['rating'] = c\n",
    "submission.to_csv('submission_gbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
